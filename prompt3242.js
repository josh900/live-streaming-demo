{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Sample repo:\n```\nThe following text is a Git repository with code. The structure of the text are sections that begin with ----, followed by a single line containing the file path and file name, followed by a variable amount of lines containing the file contents. The text representing the Git repository ends when the symbols --END-- are encounted. Any further text beyond --END-- are meant to be interpreted as instructions using the aforementioned Git repository as context.\n----\nREADME.md\n# Streaming Live Demo by D-ID\n\n* (install express) Open a terminal in the folder and run - `npm install express`\n* (add your API key) Edit the `api.json` inside the uncompressed folder and replace the emoji with your key\n* (select service) in the same `api.json` file, edit the `service` field to choose your avatar type, use `talks` for an avatar made from an image or `clips` to use a premade HQ avatar from a video\n\n## Start Streaming Demo:\n* (bring up the app) in the folder (ctr left click on folder through finder) open the terminal run `node app.js`\n* you should see this message - server started on port localhost:3000\n* (open the app) In the browser add localhost:3000\n* (connect) press connect you should see the connection ready \n* (stream) Press the start button to start streaming\n<img src=\"./app.png\" alt=\"Streaming App\" width=\"200\"/>\n\n## ⭐ Start Agents Demo [NEW!] ⭐\n* (bring up the app) in the folder (ctr left click on folder through finder) open the terminal `run node app.js` \n* you should see this message - server started on port localhost:3000\n* (open the app) In the browser add localhost:3000/agents\n* press 'Create new Agent with Knowledge' to create a new Agent. All API endpoints' responses are visible in the console. \n* press 'Connect' to connect to the agent, once done, type a message and press 'Send' to start a chat\n* you can store the created `agentId` and `chatID` variables and at the bottom of the `agents-client-api.js` file for future chats with your newly created Agent.\n![app](./agents_app.png)\n\n----\nagents-client-api.js\n'use strict';\nconst fetchJsonFile = await fetch(\"./api.json\")\nconst DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\nconst RTCPeerConnection = (\n  window.RTCPeerConnection ||\n  window.webkitRTCPeerConnection ||\n  window.mozRTCPeerConnection\n).bind(window);\n\nlet peerConnection;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet agentId;\nlet chatId;\n\nconst videoElement = document.getElementById('video-element');\nvideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\nconst agentIdLabel = document.getElementById('agentId-label');\nconst chatIdLabel = document.getElementById('chatId-label');\nconst textArea = document.getElementById(\"textArea\");\n\n// Play the idle video when the page is loaded\nwindow.onload = (event) => {\n\n  playIdleVideo()\n\n  if (agentId == \"\" || agentId == undefined) {\n    console.log(\"Empty 'agentID' and 'chatID' variables\\n\\n1. Click on the 'Create new Agent with Knowledge' button\\n2. Open the Console and wait for the process to complete\\n3. Press on the 'Connect' button\\n4. Type and send a message to the chat\\nNOTE: You can store the created 'agentID' and 'chatId' variables at the bottom of the JS file for future chats\")\n  } else {\n    console.log(\"You are good to go!\\nClick on the 'Connect Button', Then send a new message\\nAgent ID: \", agentId, \"\\nChat ID: \", chatId)\n    agentIdLabel.innerHTML = agentId\n    chatIdLabel.innerHTML = chatId\n  }\n}\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({ iceServers });\n    peerConnection.addEventListener('icegatheringstatechang e', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  console.log('set remote sdp OK');\n\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  console.log('create local sdp OK');\n\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n  console.log('set local sdp OK');\n\n\n  // Data Channel creation (for dispalying the Agent's responses as text)\n  let dc = await peerConnection.createDataChannel(\"JanusDataChannel\");\n  dc.onopen = () => {\n    console.log(\"datachannel open\");\n  };\n\n  let decodedMsg;\n  // Agent Text Responses - Decoding the responses, pasting to the HTML element\n  dc.onmessage = (event) => {\n    let msg = event.data\n    let msgType = \"chat/answer:\"\n    if (msg.includes(msgType)) {\n      msg = decodeURIComponent(msg.replace(msgType, \"\"))\n      console.log(msg)\n      decodedMsg = msg\n      return decodedMsg\n    }\n    if (msg.includes(\"stream/started\")) {\n      console.log(msg)\n      document.getElementById(\"msgHistory\").innerHTML += `<span>${decodedMsg}</span><br><br>`\n    }\n    else {\n      console.log(msg)\n    }\n  };\n\n  dc.onclose = () => {\n    console.log(\"datachannel close\");\n  };\n\n  return sessionClientAnswer;\n}\nfunction onIceGatheringStateChange() {\n  iceGatheringStatusLabel.innerText = peerConnection.iceGatheringState;\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n}\nfunction onIceCandidate(event) {\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n    // WEBRTC API CALL 3 - Submit network information\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        candidate,\n        sdpMid,\n        sdpMLineIndex,\n        session_id: sessionId,\n      }),\n    });\n  }\n}\nfunction onIceConnectionStateChange() {\n  iceStatusLabel.innerText = peerConnection.iceConnectionState;\n  iceStatusLabel.className = 'iceConnectionState-' + peerConnection.iceConnectionState;\n  if (peerConnection.iceConnectionState === 'failed' || peerConnection.iceConnectionState === 'closed') {\n    stopAllStreams();\n    closePC();\n  }\n}\nfunction onConnectionStateChange() {\n  // not supported in firefox\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n}\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n  signalingStatusLabel.className = 'signalingState-' + peerConnection.signalingState;\n}\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n  if (videoIsPlaying) {\n    status = 'streaming';\n\n    const remoteStream = stream;\n    setVideoElement(remoteStream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n  }\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n}\nfunction onTrack(event) {\n  /**\n   * The following code is designed to provide information about wether currently there is data\n   * that's being streamed - It does so by periodically looking for changes in total stream data size\n   *\n   * This information in our case is used in order to show idle video while no video is streaming.\n   * To create this idle video use the POST https://api.d-id.com/talks (or clips) endpoint with a silent audio file or a text script with only ssml breaks\n   * https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html#break-tag\n   * for seamless results use `config.fluent: true` and provide the same configuration as the streaming video\n   */\n\n  if (!event.track) return;\n\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n        if (videoStatusChanged) {\n          videoIsPlaying = report.bytesReceived > lastBytesReceived;\n          onVideoStatusChange(videoIsPlaying, event.streams[0]);\n        }\n        lastBytesReceived = report.bytesReceived;\n      }\n    });\n  }, 500);\n}\nfunction setVideoElement(stream) {\n  if (!stream) return;\n  // Add Animation Class\n  videoElement.classList.add(\"animated\")\n\n  // Removing browsers' autoplay's 'Mute' Requirement\n  videoElement.muted = false;\n\n  videoElement.srcObject = stream;\n  videoElement.loop = false;\n\n  // Remove Animation Class after it's completed\n  setTimeout(() => {\n    videoElement.classList.remove(\"animated\")\n  }, 1000);\n\n  // safari hotfix\n  if (videoElement.paused) {\n    videoElement\n      .play()\n      .then((_) => { })\n      .catch((e) => { });\n  }\n}\nfunction playIdleVideo() {\n  // Add Animation Class\n  videoElement.classList.toggle(\"animated\")\n\n  videoElement.srcObject = undefined;\n  videoElement.src = 'emma_idle.mp4';\n  videoElement.loop = true;\n\n  // Remove Animation Class after it's completed\n  setTimeout(() => {\n    videoElement.classList.remove(\"animated\")\n  }, 1000);\n}\nfunction stopAllStreams() {\n  if (videoElement.srcObject) {\n    console.log('stopping video streams');\n    videoElement.srcObject.getTracks().forEach((track) => track.stop());\n    videoElement.srcObject = null;\n  }\n}\nfunction closePC(pc = peerConnection) {\n  if (!pc) return;\n  console.log('stopping peer connection');\n  pc.close();\n  pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n  pc.removeEventListener('icecandidate', onIceCandidate, true);\n  pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  clearInterval(statsIntervalId);\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n  }\n}\nconst maxRetryCount = 3;\nconst maxDelaySec = 4;\nasync function fetchWithRetries(url, options, retries = 1) {\n  try {\n    return await fetch(url, options);\n  } catch (err) {\n    if (retries <= maxRetryCount) {\n      const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 1000;\n\n      await new Promise((resolve) => setTimeout(resolve, delay));\n\n      console.log(`Request failed, retrying ${retries}/${maxRetryCount}. Error ${err}`);\n      return fetchWithRetries(url, options, retries + 1);\n    } else {\n      throw new Error(`Max retries exceeded. error: ${err}`);\n    }\n  }\n}\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n  if (agentId == \"\" || agentId === undefined) {\n    return alert(\"1. Click on the 'Create new Agent with Knowledge' button\\n2. Open the Console and wait for the process to complete\\n3. Press on the 'Connect' button\\n4. Type and send a message to the chat\\nNOTE: You can store the created 'agentID' and 'chatId' variables at the bottom of the JS file for future chats\")\n  }\n\n  if (peerConnection && peerConnection.connectionState === 'connected') {\n    return;\n  }\n  stopAllStreams();\n  closePC();\n\n  // WEBRTC API CALL 1 - Create a new stream\n  const sessionResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      source_url: 'https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg'\n    }),\n  });\n\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n  streamId = newStreamId;\n  sessionId = newSessionId;\n  try {\n    sessionClientAnswer = await createPeerConnection(offer, iceServers);\n  } catch (e) {\n    console.log('error during streaming setup', e);\n    stopAllStreams();\n    closePC();\n    return;\n  }\n\n  // WEBRTC API CALL 2 - Start a stream\n  const sdpResponse = await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/sdp`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      answer: sessionClientAnswer,\n      session_id: sessionId,\n    }),\n  });\n};\n\nconst startButton = document.getElementById('start-button');\nstartButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') {\n\n    // Pasting the user's message to the Chat History element\n    document.getElementById(\"msgHistory\").innerHTML += `<span style='opacity:0.5'><u>User:</u> ${textArea.value}</span><br>`\n\n    // Storing the Text Area value\n    let txtAreaValue = document.getElementById(\"textArea\").value\n\n    // Clearing the text-box element\n    document.getElementById(\"textArea\").value = \"\"\n\n\n    // Agents Overview - Step 3: Send a Message to a Chat session - Send a message to a Chat\n    const playResponse = await fetchWithRetries(`${DID_API.url}/agents/${agentId}/chat/${chatId}`, {\n      method: 'POST',\n      headers: {\n        'Authorization': `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        \"streamId\": streamId,\n        \"sessionId\": sessionId,\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": txtAreaValue,\n            \"created_at\": new Date().toString()\n          }\n        ]\n      }),\n    });\n    const playResponseData = await playResponse.json();\n    if (playResponse.status === 200 && playResponseData.chatMode === 'TextOnly') {\n      console.log('User is out of credit, API only return text messages');\n      document.getElementById(\n        'msgHistory'\n      ).innerHTML += `<span style='opacity:0.5'> ${playResponseData.result}</span><br>`;\n    }\n  }\n};\n\nconst destroyButton = document.getElementById('destroy-button');\ndestroyButton.onclick = async () => {\n  await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n    method: 'DELETE',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ session_id: sessionId }),\n  });\n\n  stopAllStreams();\n  closePC();\n};\n\n// Agents API Workflow\nasync function agentsAPIworkflow() {\n  agentIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  chatIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  axios.defaults.baseURL = `${DID_API.url}`;\n  axios.defaults.headers.common['Authorization'] = `Basic ${DID_API.key}`\n  axios.defaults.headers.common['content-type'] = 'application/json'\n\n  // Retry Mechanism (Polling) for this demo only - Please use Webhooks in real life applications! \n  // as described in https://docs.d-id.com/reference/knowledge-overview#%EF%B8%8F-step-2-add-documents-to-the-knowledge-base\n  async function retry(url, retries = 1) {\n    const maxRetryCount = 5; // Maximum number of retries\n    const maxDelaySec = 10; // Maximum delay in seconds\n    try {\n      let response = await axios.get(`${url}`)\n      if (response.data.status == \"done\") {\n        return console.log(response.data.id + \": \" + response.data.status)\n      }\n      else {\n        throw new Error(\"Status is not 'done'\")\n      }\n    } catch (err) {\n      if (retries <= maxRetryCount) {\n        const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 1000;\n\n        await new Promise((resolve) => setTimeout(resolve, delay));\n\n        console.log(`Retrying ${retries}/${maxRetryCount}. ${err}`);\n        return retry(url, retries + 1);\n      } else {\n        agentIdLabel.innerHTML = `<span style='color:red'>Failed</span>`\n        chatIdLabel.innerHTML = `<span style='color:red'>Failed</span>`\n        throw new Error(`Max retries exceeded. error: ${err}`);\n      }\n    }\n  }\n\n  // Knowledge Overview - Step 1: Create a new Knowledge Base\n  // https://docs.d-id.com/reference/knowledge-overview#%EF%B8%8F-step-1-create-a-new-knowledge-base\n  const createKnowledge = await axios.post('/knowledge',\n    {\n      name: \"knowledge\",\n      description: \"D-ID Agents API\"\n    })\n  console.log(\"Create Knowledge:\", createKnowledge.data)\n\n  let knowledgeId = createKnowledge.data.id\n  console.log(\"Knowledge ID: \" + knowledgeId)\n\n  // Knowledge Overview - Step 2: Add Documents to the Knowledge Base\n  // https://docs.d-id.com/reference/knowledge-overview#%EF%B8%8F-step-2-add-documents-to-the-knowledge-base\n\n  const createDocument = await axios.post(`/knowledge/${knowledgeId}/documents`,\n    {\n      \"documentType\": \"pdf\",\n      \"source_url\": \"https://d-id-public-bucket.s3.us-west-2.amazonaws.com/Prompt_engineering_Wikipedia.pdf\",\n      \"title\": \"Prompt Engineering Wikipedia Page PDF\",\n    })\n  console.log(\"Create Document: \", createDocument.data)\n\n  // Split the # to use in documentID\n  let documentId = createDocument.data.id\n  let splitArr = documentId.split(\"#\")\n  documentId = splitArr[1]\n  console.log(\"Document ID: \" + documentId)\n\n\n  // Knowledge Overview - Step 3: Retrieving the Document and Knowledge status\n  // https://docs.d-id.com/reference/knowledge-overview#%EF%B8%8F-step-3-retrieving-the-document-and-knowledge-status\n  await retry(`/knowledge/${knowledgeId}/documents/${documentId}`)\n  await retry(`/knowledge/${knowledgeId}`)\n\n  // Agents Overview - Step 1: Create an Agent\n  // https://docs.d-id.com/reference/agents-overview#%EF%B8%8F-step-1-create-an-agent\n  const createAgent = await axios.post('/agents',\n    {\n      \"knowledge\": {\n        \"provider\": \"pinecone\",\n        \"embedder\": {\n          \"provider\": \"pinecone\",\n          \"model\": \"ada02\"\n        },\n        \"id\": knowledgeId\n      },\n      \"presenter\": {\n        \"type\": \"talk\",\n        \"voice\": {\n          \"type\": \"microsoft\",\n          \"voice_id\": \"en-US-JennyMultilingualV2Neural\"\n        },\n        \"thumbnail\": \"https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg\",\n        \"source_url\": \"https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg\"\n      },\n      \"llm\": {\n        \"type\": \"openai\",\n        \"provider\": \"openai\",\n        \"model\": \"gpt-3.5-turbo-1106\",\n        \"instructions\": \"Your name is Emma, an AI designed to assist with information about Prompt Engineering and RAG\"\n      },\n      \"preview_name\": \"Emma\"\n    }\n\n  )\n  console.log(\"Create Agent: \", createAgent.data)\n  let agentId = createAgent.data.id\n  console.log(\"Agent ID: \" + agentId)\n\n  // Agents Overview - Step 2: Create a new Chat session with the Agent\n  // https://docs.d-id.com/reference/agents-overview#%EF%B8%8F-step-2-create-a-new-chat-session-with-the-agent\n  const createChat = await axios.post(`/agents/${agentId}/chat`)\n  console.log(\"Create Chat: \", createChat.data)\n  let chatId = createChat.data.id\n  console.log(\"Chat ID: \" + chatId)\n\n  // Agents Overview - Step 3: Send a Message to a Chat session\n  // https://docs.d-id.com/reference/agents-overview#%EF%B8%8F-step-3--send-a-message-to-a-chat-session\n  // The WebRTC steps are called in the functions: 'connectButton.onclick', onIceCandidate(event), 'startButton.onclick'\n\n  console.log(\"Create new Agent with Knowledge - DONE!\\n Press on the 'Connect' button to proceed.\\n Store the created 'agentID' and 'chatId' variables at the bottom of the JS file for future chats\")\n  agentIdLabel.innerHTML = agentId\n  chatIdLabel.innerHTML = chatId\n  return { agentId: agentId, chatId: chatId }\n\n}\n\nconst agentsButton = document.getElementById(\"agents-button\")\nagentsButton.onclick = async () => {\n  try{\n    const agentsIds = {} = await agentsAPIworkflow()\n    console.log(agentsIds)\n    agentId = agentsIds.agentId\n    chatId = agentsIds.chatId\n    return\n  }\n  catch(err){\n    agentIdLabel.innerHTML = `<span style='color:red'>Failed</span>`\n    chatIdLabel.innerHTML = `<span style='color:red'>Failed</span>`\n    throw new Error(err)\n  }\n}\n\n// Paste Your Created Agent and Chat IDs Here:\nagentId = \"\"\nchatId = \"\"\n\n----\napi.json\n{\n    \"key\": \"🤫\",\n    \"url\": \"https://api.d-id.com\",\n    \"service\": \"talks\"\n}\n----\napp.js\nconst express = require('express');\nconst http = require('http');\nconst cors = require('cors');\n\nconst port = 3000;\n\nconst app = express();\napp.use(cors({ origin: 'http://localhost:3000' }));\n\napp.use('/', express.static(__dirname));\n\napp.get('/', function(req, res) {\n    res.sendFile(__dirname + '/index.html')\n});\napp.get('/agents', function(req, res) {\n    res.sendFile(__dirname + '/index-agents.html')\n});\n\nconst server = http.createServer(app);\n\nserver.listen(port, () => console.log(`Server started on port localhost:${port}\\nhttp://localhost:${port}\\nhttp://localhost:${port}/agents`));\n\n----\nindex-agents.html\n<!DOCTYPE html>\n<html>\n\n<head>\n  <title>D-ID Agents API Demo</title>\n  <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n  <link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\" rel=\"stylesheet\" />\n  <link rel=\"stylesheet\" href=\"style-agents.css\">\n  <link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://studio.d-id.com/favicon/favicon-192x192.png\">\n</head>\n\n<body>\n  <div id=\"content\">\n\n    <div id=\"status\">\n      <h4>Agent Status</h4>\n      Agent ID: <label id=\"agentId-label\"></label><br />\n      Chat ID: <label id=\"chatId-label\"></label><br />\n      <br>\n      <h4>WebRTC Connection Status</h4>\n      ICE gathering status: <label id=\"ice-gathering-status-label\"></label><br />\n      ICE status: <label id=\"ice-status-label\"></label><br />\n      Peer connection status: <label id=\"peer-status-label\"></label><br />\n      Signaling status: <label id=\"signaling-status-label\"></label><br />\n      Streaming status: <label id=\"streaming-status-label\"></label><br />\n      <br>\n      <div id=\"buttons\">\n        <button id=\"agents-button\" type=\"button\">Create new Agent with Knowledge</button>\n        <br><br>\n        <button id=\"connect-button\" type=\"button\">Connect</button>\n        <button id=\"destroy-button\" type=\"button\">Destroy</button>\n      </div>\n    </div>\n\n    <div id=\"video-wrapper\">\n      <div>\n        <video id=\"video-element\" width=\"400\" height=\"400\" src=\"\" autoplay loop muted class=\"animated\"></video>\n      </div>\n    </div>\n\n    <div class=\"chat\">\n      <h4>Chat History</h4>\n      <div id=\"msgHistory\">\n      </div>\n    </div>\n\n  </div>\n\n  <div>\n    <h3>Type your message here:</h3>\n    <textarea id=\"textArea\" cols=\"50\" rows=\"5\" maxlength=\"280\"></textarea>\n    <br>\n    <button id=\"start-button\" type=\"button\">Send</button>\n  </div>\n\n  <script type=\"module\" src=\"./agents-client-api.js\"></script>\n  <script src=\"https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js\"></script>\n</body>\n\n</html>\n----\nindex-agents.js\nimport './agents-client-api.js';\n\n----\nindex.html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>D-ID Streaming POC</title>\n    <!-- added google fonts -->\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n    <link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\" rel=\"stylesheet\" />\n\n    <style>\n      .peerConnectionState-new {\n        color: cornflowerblue;\n      }\n      .peerConnectionState-connecting {\n        color: orange;\n      }\n      .peerConnectionState-connected {\n        color: green;\n      }\n      .peerConnectionState-disconnected,\n      .peerConnectionState-closed,\n      .peerConnectionState-failed {\n        color: red;\n      }\n\n      .iceConnectionState-new {\n        color: cornflowerblue;\n      }\n      .iceConnectionState-checking {\n        color: orange;\n      }\n      .iceConnectionState-connected,\n      .iceConnectionState-completed {\n        color: green;\n      }\n      .peerConnectionState-disconnected,\n      .peerConnectionState-closed,\n      .peerConnectionState-failed {\n        color: red;\n      }\n\n      .iceGatheringState-new {\n        color: cornflowerblue;\n      }\n      .iceGatheringState-gathering {\n        color: orange;\n      }\n      .iceGatheringState-complete {\n        color: black;\n      }\n\n      .signalingState-stable {\n        color: green;\n      }\n      .signalingState-have-local-offer,\n      .signalingState-have-remote-offer,\n      .signalingState-have-local-pranswer,\n      .signalingState-have-remote-pranswer {\n        color: cornflowerblue;\n      }\n      .signalingState-closed {\n        color: red;\n      }\n\n      .streamingState-streaming {\n        color: green;\n      }\n\n      .streamingState-empty {\n        color: grey;\n      }\n\n      .streamEvent-started {\n        color: green;\n      }\n\n      .streamEvent-done {\n        color: orange;\n      }\n\n      .streamEvent-ready {\n        color: green;\n      }\n\n      .streamEvent-error {\n        color: red;\n      }\n\n      .streamEvent-dont-care {\n        color: gray;\n      }\n\n      /* added css from here */\n\n      body * {\n        font-family: 'Mulish', sans-serif;\n        text-align: center;\n      }\n\n      #content {\n        width: 820px;\n        position: relative;\n        margin: 0 auto;\n      }\n\n      #buttons {\n        clear: both;\n        padding: 0 0 0 0;\n        text-align: center;\n      }\n\n      button {\n        padding: 10px 20px;\n        border-radius: 5px;\n        border: none;\n        font-size: 16px;\n        margin: 0 5px;\n        background-color: #7459fe;\n        color: #fff;\n      }\n\n      button:hover {\n        background-color: #9480ff;\n        cursor: pointer;\n        transition: all 0.2s ease-out;\n      }\n\n      #status {\n        clear: both;\n        padding: 20px 0 0 0;\n        text-align: left;\n        display: inline-block;\n        zoom: 1;\n        line-height: 140%;\n        font-size: 15px;\n      }\n\n      #status div {\n        padding-bottom: 10px;\n      }\n\n      #video-wrapper {\n        background: url(bg.png);\n        height: 500px;\n        background-position: top;\n      }\n\n      #video-wrapper div {\n        position: relative;\n        height: 100%;\n        width: 400px;\n        margin: 0 auto;\n      }\n\n      video {\n        position: absolute;\n        top: 50%;\n        left: 50%;\n        transform: translate(-50%, -50%);\n        /*border:1px solid;*/\n        border-radius: 50%;\n        background-color: #fff;\n      }\n    </style>\n  </head>\n\n  <body>\n    <!-- adde \"id=content\" -->\n    <div id=\"content\">\n      <!-- added \"id=video-wrapper\" -->\n      <div id=\"video-wrapper\">\n        <div>\n          <video id=\"idle-video-element\" width=\"400\" height=\"400\" autoplay loop style=\"opacity: 1\"></video>\n          <video id=\"stream-video-element\" width=\"400\" height=\"400\" autoplay style=\"opacity: 0\"></video>\n        </div>\n      </div>\n      <br />\n\n      <!-- added div#buttons -->\n      <div id=\"buttons\">\n        <button id=\"connect-button\" type=\"button\">Connect</button>\n        <button id=\"start-button\" type=\"button\">Start</button>\n        <button id=\"destroy-button\" type=\"button\">Destroy</button>\n      </div>\n\n      <!-- added div#status -->\n      <div id=\"status\">\n        <!-- removed the wrapping <div> tags -->\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label><br />\n        ICE status: <label id=\"ice-status-label\"></label><br />\n        Peer connection status: <label id=\"peer-status-label\"></label><br />\n        Signaling status: <label id=\"signaling-status-label\"></label><br />\n        Last stream event: <label id=\"stream-event-label\"></label><br />\n        Streaming status: <label id=\"streaming-status-label\"></label><br />\n      </div>\n    </div>\n\n    <script type=\"module\" src=\"./index.js\"></script>\n  </body>\n</html>\n\n----\nindex.js\nimport './streaming-client-api.js';\n\n----\npackage.json\n{\n  \"dependencies\": {\n    \"cors\": \"^2.8.5\",\n    \"express\": \"^4.18.2\"\n  },\n  \"scripts\": {\n    \"dev\": \"node app.js\"\n  }\n}\n\n----\nstreaming-client-api.js\n'use strict';\nconst fetchJsonFile = await fetch(\"./api.json\")\nconst DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\nconst RTCPeerConnection = (\n  window.RTCPeerConnection ||\n  window.webkitRTCPeerConnection ||\n  window.mozRTCPeerConnection\n).bind(window);\n\nlet peerConnection;\nlet pcDataChannel;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\n\nlet statsIntervalId;\nlet lastBytesReceived;\nlet videoIsPlaying = false;\nlet streamVideoOpacity = 0;\n\n// Set this variable to true to request stream warmup upon connection to mitigate potential jittering issues\nconst stream_warmup = true;\nlet isStreamReady = !stream_warmup;\n\nconst idleVideoElement = document.getElementById('idle-video-element');\nconst streamVideoElement = document.getElementById('stream-video-element');\nidleVideoElement.setAttribute('playsinline', '');\nstreamVideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\nconst streamEventLabel = document.getElementById('stream-event-label');\n\nconst presenterInputByService = {\n  talks: {\n    source_url: 'https://d-id-public-bucket.s3.amazonaws.com/or-roman.jpg',\n  },\n  clips: {\n    presenter_id: 'rian-lZC6MmWfC1',\n    driver_id: 'mXra4jY38i',\n  },\n};\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n  if (peerConnection && peerConnection.connectionState === 'connected') {\n    return;\n  }\n\n  stopAllStreams();\n  closePC();\n\n  /**\n   * Set 'stream_warmup' to 'true' in the payload to initiate idle streaming at the beginning of the connection, addressing jittering issues.\n   * The idle streaming process is transparent to the user and is concealed by triggering a 'stream/ready' event on the data channel,\n   * indicating that idle streaming has concluded and the stream channel is ready for use.\n   */\n  const sessionResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ ...presenterInputByService[DID_API.service], stream_warmup }),\n  });\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n  streamId = newStreamId;\n  sessionId = newSessionId;\n\n  try {\n    sessionClientAnswer = await createPeerConnection(offer, iceServers);\n  } catch (e) {\n    console.log('error during streaming setup', e);\n    stopAllStreams();\n    closePC();\n    return;\n  }\n\n  const sdpResponse = await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/sdp`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      answer: sessionClientAnswer,\n      session_id: sessionId,\n    }),\n  });\n};\n\nconst startButton = document.getElementById('start-button');\nstartButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (\n    (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') &&\n    isStreamReady\n  ) {\n    const playResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        script: {\n          type: 'audio',\n          audio_url: 'https://d-id-public-bucket.s3.us-west-2.amazonaws.com/webrtc.mp3',\n        },\n        ...(DID_API.service === 'clips' && {\n          background: {\n            color: '#FFFFFF',\n          },\n        }),\n        config: {\n          stitch: true,\n        },\n        session_id: sessionId,\n      }),\n    });\n  }\n};\n\nconst destroyButton = document.getElementById('destroy-button');\ndestroyButton.onclick = async () => {\n  await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n    method: 'DELETE',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ session_id: sessionId }),\n  });\n\n  stopAllStreams();\n  closePC();\n};\n\nfunction onIceGatheringStateChange() {\n  iceGatheringStatusLabel.innerText = peerConnection.iceGatheringState;\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n}\nfunction onIceCandidate(event) {\n  console.log('onIceCandidate', event);\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        candidate,\n        sdpMid,\n        sdpMLineIndex,\n        session_id: sessionId,\n      }),\n    });\n  } else {\n    // For the initial 2 sec idle stream at the beginning of the connection, we utilize a null ice candidate.\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        session_id: sessionId,\n      }),\n    });\n  }\n}\nfunction onIceConnectionStateChange() {\n  iceStatusLabel.innerText = peerConnection.iceConnectionState;\n  iceStatusLabel.className = 'iceConnectionState-' + peerConnection.iceConnectionState;\n  if (peerConnection.iceConnectionState === 'failed' || peerConnection.iceConnectionState === 'closed') {\n    stopAllStreams();\n    closePC();\n  }\n}\nfunction onConnectionStateChange() {\n  // not supported in firefox\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n  if (peerConnection.connectionState === 'connected') {\n    playIdleVideo();\n    /**\n     * A fallback mechanism: if the 'stream/ready' event isn't received within 5 seconds after asking for stream warmup,\n     * it updates the UI to indicate that the system is ready to start streaming data.\n     */\n    setTimeout(() => {\n      if (!isStreamReady) {\n        console.log('forcing stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }\n    }, 5000);\n  }\n}\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n  signalingStatusLabel.className = 'signalingState-' + peerConnection.signalingState;\n}\n\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n\n  if (videoIsPlaying) {\n    status = 'streaming';\n    streamVideoOpacity = isStreamReady ? 1 : 0;\n    setStreamVideoElement(stream);\n  } else {\n    status = 'empty';\n    streamVideoOpacity = 0;\n  }\n\n  streamVideoElement.style.opacity = streamVideoOpacity;\n  idleVideoElement.style.opacity = 1 - streamVideoOpacity;\n\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n}\n\nfunction onTrack(event) {\n  /**\n   * The following code is designed to provide information about wether currently there is data\n   * that's being streamed - It does so by periodically looking for changes in total stream data size\n   *\n   * This information in our case is used in order to show idle video while no video is streaming.\n   * To create this idle video use the POST https://api.d-id.com/talks (or clips) endpoint with a silent audio file or a text script with only ssml breaks\n   * https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html#break-tag\n   * for seamless results use `config.fluent: true` and provide the same configuration as the streaming video\n   */\n\n  if (!event.track) return;\n\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n        if (videoStatusChanged) {\n          videoIsPlaying = report.bytesReceived > lastBytesReceived;\n          onVideoStatusChange(videoIsPlaying, event.streams[0]);\n        }\n        lastBytesReceived = report.bytesReceived;\n      }\n    });\n  }, 500);\n}\n\nfunction onStreamEvent(message) {\n  /**\n   * This function handles stream events received on the data channel.\n   * The 'stream/ready' event received on the data channel signals the end of the 2sec idle streaming.\n   * Upon receiving the 'ready' event, we can display the streamed video if one is available on the stream channel.\n   * Until the 'ready' event is received, we hide any streamed video.\n   * Additionally, this function processes events for stream start, completion, and errors. Other data events are disregarded.\n   */\n\n  if (pcDataChannel.readyState === 'open') {\n    let status;\n    const [event, _] = message.data.split(':');\n\n    switch (event) {\n      case 'stream/started':\n        status = 'started';\n        break;\n      case 'stream/done':\n        status = 'done';\n        break;\n      case 'stream/ready':\n        status = 'ready';\n        break;\n      case 'stream/error':\n        status = 'error';\n        break;\n      default:\n        status = 'dont-care';\n        break;\n    }\n\n    // Set stream ready after a short delay, adjusting for potential timing differences between data and stream channels\n    if (status === 'ready') {\n      setTimeout(() => {\n        console.log('stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }, 1000);\n    } else {\n      console.log(event);\n      streamEventLabel.innerText = status === 'dont-care' ? event : status;\n      streamEventLabel.className = 'streamEvent-' + status;\n    }\n  }\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({ iceServers });\n    pcDataChannel = peerConnection.createDataChannel('JanusDataChannel');\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n    pcDataChannel.addEventListener('message', onStreamEvent, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  console.log('set remote sdp OK');\n\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  console.log('create local sdp OK');\n\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n  console.log('set local sdp OK');\n\n  return sessionClientAnswer;\n}\n\nfunction setStreamVideoElement(stream) {\n  if (!stream) return;\n\n  streamVideoElement.srcObject = stream;\n  streamVideoElement.loop = false;\n  streamVideoElement.mute = !isStreamReady;\n\n  // safari hotfix\n  if (streamVideoElement.paused) {\n    streamVideoElement\n      .play()\n      .then((_) => {})\n      .catch((e) => {});\n  }\n}\n\nfunction playIdleVideo() {\n  idleVideoElement.src = DID_API.service == 'clips' ? 'rian_idle.mp4' : 'or_idle.mp4';\n}\n\nfunction stopAllStreams() {\n  if (streamVideoElement.srcObject) {\n    console.log('stopping video streams');\n    streamVideoElement.srcObject.getTracks().forEach((track) => track.stop());\n    streamVideoElement.srcObject = null;\n    streamVideoOpacity = 0;\n  }\n}\n\nfunction closePC(pc = peerConnection) {\n  if (!pc) return;\n  console.log('stopping peer connection');\n  pc.close();\n  pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n  pc.removeEventListener('icecandidate', onIceCandidate, true);\n  pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  pc.removeEventListener('onmessage', onStreamEvent, true);\n\n  clearInterval(statsIntervalId);\n  isStreamReady = !stream_warmup;\n  streamVideoOpacity = 0;\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  streamEventLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n  }\n}\n\nconst maxRetryCount = 3;\nconst maxDelaySec = 4;\n\nasync function fetchWithRetries(url, options, retries = 1) {\n  try {\n    return await fetch(url, options);\n  } catch (err) {\n    if (retries <= maxRetryCount) {\n      const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 1000;\n\n      await new Promise((resolve) => setTimeout(resolve, delay));\n\n      console.log(`Request failed, retrying ${retries}/${maxRetryCount}. Error ${err}`);\n      return fetchWithRetries(url, options, retries + 1);\n    } else {\n      throw new Error(`Max retries exceeded. error: ${err}`);\n    }\n  }\n}\n\n----\nstyle-agents.css\n.peerConnectionState-new {\n  color: cornflowerblue;\n}\n.peerConnectionState-connecting {\n  color: orange;\n}\n.peerConnectionState-connected {\n  color: green;\n}\n.peerConnectionState-disconnected,\n.peerConnectionState-closed,\n.peerConnectionState-failed {\n  color: red;\n}\n\n.iceConnectionState-new {\n  color: cornflowerblue;\n}\n.iceConnectionState-checking {\n  color: orange;\n}\n.iceConnectionState-connected,\n.iceConnectionState-completed {\n  color: green;\n}\n.peerConnectionState-disconnected,\n.peerConnectionState-closed,\n.peerConnectionState-failed {\n  color: red;\n}\n\n.iceGatheringState-new {\n  color: cornflowerblue;\n}\n.iceGatheringState-gathering {\n  color: orange;\n}\n.iceGatheringState-complete {\n  color: black;\n}\n\n.signalingState-stable {\n  color: green;\n}\n.signalingState-have-local-offer,\n.signalingState-have-remote-offer,\n.signalingState-have-local-pranswer,\n.signalingState-have-remote-pranswer {\n  color: cornflowerblue;\n}\n.signalingState-closed {\n  color: red;\n}\n\n.streamingState-streaming {\n  color: green;\n}\n\n.streamingState-empty {\n  color: grey;\n}\n\n#agentId-label, #chatId-label{\n  color: green;\n}\n\n/* added css from here */\n\nbody * {\n  font-family: 'Mulish', sans-serif;\n  text-align: center;\n}\n\n#content {\n  display: flex;\n  flex-direction: row;\n  justify-content: space-evenly;\n  margin-top: 50px;\n}\n\n#buttons {\n  clear: both;\n  padding: 0 0 0 0;\n  text-align: center;\n}\n\nbutton {\n  padding: 10px 20px;\n  border-radius: 5px;\n  border: none;\n  font-size: 16px;\n  margin: 0 5px;\n  background-color: #7459fe;\n  color: #fff;\n}\n\nbutton#connect-button {\nbackground-color: green;\n}\nbutton#destroy-button{\n  background-color: red;\n}\n\nbutton#start-button{\n  margin: 1em;\n}\n\nbutton:hover, #destroy-button:hover,#connect-button:hover {\n  filter: brightness(85%);\n  cursor: pointer;\n  transition: all 0.2s ease-out;\n}\n\nh4{\n  margin: 0;\n  margin-bottom: 10px;\n}\n\ntextarea {\n  font-size: 16px;\n  text-align: center;\n  width: 500px;\n  border-radius: 5px;\n  padding: 10px 20px;\n  border: 2px solid #7459fe;\n  font-size: 16px;\n  margin: 0 5px;\n}\n\n#msgHistory {\n  overflow-y: auto;\n  line-break: loose;\n}\n\n#status {\n  display: inline-block;\n  zoom: 1;\n  line-height: 140%;\n  font-size: 15px;\n  width: 400px;\n}\n\n#status div {\n  padding-bottom: 10px;\n}\n\n#video-wrapper {\n  /* height: 500px; */\n  width: 400px;\n  height: 400px;\n  background-position: top;\n}\n\n.chat{\n  width: 400px;\n}\n\n\nvideo {\n  /* display: block; */\n  border-radius: 50%;\n  background-image: url(\"emma_idle.png\");\n  background-position: top;\n  /* position: absolute; */\n  background-size: contain;\n}\n\n.animated {\n  animation: opacityAnimation 0.2s ease-in-out;\n}\n\n@keyframes opacityAnimation {\nfrom { opacity: 0.8; }\nto { opacity: 1; }\n}\n\n--END--\n\n\nGroq Docs:\n---\nChat\nCreate chat completion\nPOST\nhttps://api.groq.com/openai/v1/chat/completions\n\nCreates a model response for the given chat conversation.\n\nRequest Body\nfrequency_penalty\nnumber or null\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nfunction_call\nDeprecated\nstring / object or null\nOptional\nDeprecated in favor of tool_choice.\n\nControls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"name\": \"my_function\"} forces the model to call that function.\n\nnone is the default when no functions are present. auto is the default if functions are present.\n\nShow possible types\nfunctions\nDeprecated\narray or null\nOptional\nDeprecated in favor of tools.\n\nA list of functions the model may generate JSON inputs for.\n\nShow properties\nlogit_bias\nobject or null\nOptional\nDefaults to null\nThis is not yet supported by any of our models. Modify the likelihood of specified tokens appearing in the completion.\n\nlogprobs\nboolean or null\nOptional\nDefaults to false\nThis is not yet supported by any of our models. Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.\n\nmax_tokens\ninteger or null\nOptional\nThe maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.\n\nmessages\narray\nRequired\nA list of messages comprising the conversation so far.\n\nShow possible types\nmodel\nstring\nRequired\nID of the model to use. For details on which models are compatible with the Chat API, see available models\n\nn\ninteger or null\nOptional\nDefaults to 1\nHow many chat completion choices to generate for each input message. Note that the current moment, only n=1 is supported. Other values will result in a 400 response.\n\nparallel_tool_calls\nboolean or null\nOptional\nDefaults to true\nWhether to enable parallel function calling during tool use.\n\npresence_penalty\nnumber or null\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nresponse_format\nobject or null\nOptional\nAn object specifying the format that the model must output.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message.\n\nShow properties\nseed\ninteger or null\nOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.\n\nstop\nstring / array or null\nOptional\nDefaults to null\nUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n\nShow possible types\nstream\nboolean or null\nOptional\nDefaults to false\nIf set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Example code.\n\nstream_options\nobject or null\nOptional\nDefaults to null\nOptions for streaming response. Only set this when you set stream: true.\n\nShow properties\ntemperature\nnumber or null\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both\n\ntool_choice\nstring / object or null\nOptional\nControls which (if any) tool is called by the model. none means the model will not call any tool and instead generates a message. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n\nnone is the default when no tools are present. auto is the default if tools are present.\n\nShow possible types\ntools\narray or null\nOptional\nA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n\nShow properties\ntop_logprobs\ninteger or null\nOptional\nThis is not yet supported by any of our models. An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.\n\ntop_p\nnumber or null\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.\n\nuser\nstring or null\nOptional\nA unique identifier representing your end-user, which can help us monitor and detect abuse.\n\nReturns\nReturns a chat completion object, or a streamed sequence of chat completion chunk objects if the request is streamed.\n\nExample request\n\nJavaScript\nCopy\n// Default\nimport Groq from \"groq-sdk\";\n\nconst groq = new Groq({ apiKey: process.env.GROQ_API_KEY });\n\nasync function main() {\n  const completion = await groq.chat.completions\n    .create({\n      messages: [\n        {\n          role: \"user\",\n          content: \"Explain the importance of fast language models\",\n        },\n      ],\n      model: \"mixtral-8x7b-32768\",\n    })\n    .then((chatCompletion) => {\n      console.log(chatCompletion.choices[0]?.message?.content || \"\");\n    });\n}\n\nmain();\nResponse\n\nCopy\n{\n  \"id\": \"34a9110d-c39d-423b-9ab9-9c748747b204\",\n  \"object\": \"chat.completion\",\n  \"created\": 1708045122,\n  \"model\": \"mixtral-8x7b-32768\",\n  \"system_fingerprint\": null,\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Low latency Large Language Models (LLMs) are important in the field of artificial intelligence and natural language processing (NLP) for several reasons:\\n\\n1. Real-time applications: Low latency LLMs are essential for real-time applications such as chatbots, voice assistants, and real-time translation services. These applications require immediate responses, and high latency can lead to a poor user experience.\\n\\n2. Improved user experience: Low latency LLMs provide a more seamless and responsive user experience. Users are more likely to continue using a service that provides quick and accurate responses, leading to higher user engagement and satisfaction.\\n\\n3. Competitive advantage: In today's fast-paced digital world, businesses that can provide quick and accurate responses to customer inquiries have a competitive advantage. Low latency LLMs can help businesses respond to customer inquiries more quickly, potentially leading to increased sales and customer loyalty.\\n\\n4. Better decision-making: Low latency LLMs can provide real-time insights and recommendations, enabling businesses to make better decisions more quickly. This can be particularly important in industries such as finance, healthcare, and logistics, where quick decision-making can have a significant impact on business outcomes.\\n\\n5. Scalability: Low latency LLMs can handle a higher volume of requests, making them more scalable than high-latency models. This is particularly important for businesses that experience spikes in traffic or have a large user base.\\n\\nIn summary, low latency LLMs are essential for real-time applications, providing a better user experience, enabling quick decision-making, and improving scalability. As the demand for real-time NLP applications continues to grow, the importance of low latency LLMs will only become more critical.\"\n      },\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 24,\n    \"completion_tokens\": 377,\n    \"total_tokens\": 401,\n    \"prompt_time\": 0.009,\n    \"completion_time\": 0.774,\n    \"total_time\": 0.783\n  }\n}\nModels\nList models\nGET\nhttps://api.groq.com/openai/v1/models\n\nList models\n\nReturns\nA list of models\n\nResponse\n\nCopy\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"gemma-7b-it\",\n      \"object\": \"model\",\n      \"created\": 1693721698,\n      \"owned_by\": \"Google\",\n      \"active\": true,\n      \"context_window\": 8192\n    },\n    {\n      \"id\": \"llama2-70b-4096\",\n      \"object\": \"model\",\n      \"created\": 1693721698,\n      \"owned_by\": \"Meta\",\n      \"active\": true,\n      \"context_window\": 4096\n    },\n    {\n      \"id\": \"mixtral-8x7b-32768\",\n      \"object\": \"model\",\n      \"created\": 1693721698,\n      \"owned_by\": \"Mistral AI\",\n      \"active\": true,\n      \"context_window\": 32768\n    }\n  ]\n}\nRetrieve model\nGET\nhttps://api.groq.com/openai/v1/models/{model}\n\nGet model\n\nReturns\nA model object\n\nResponse\n\nCopy\n{\n  \"id\": \"llama2-70b-4096\",\n  \"object\": \"model\",\n  \"created\": 1693721698,\n  \"owned_by\": \"Meta\",\n  \"active\": true,\n  \"context_window\": 4096\n}\n\n---\n\n\nDeegram docs:\n```\nThe following text is a Git repository with code. The structure of the text are sections that begin with ----, followed by a single line containing the file path and file name, followed by a variable amount of lines containing the file contents. The text representing the Git repository ends when the symbols --END-- are encounted. Any further text beyond --END-- are meant to be interpreted as instructions using the aforementioned Git repository as context.\n----\ncommitlint.config.js\nmodule.exports = { extends: [\"@commitlint/config-conventional\"] };\n\n----\nexamples\\node-live\\index.js\nconst { createClient, LiveTranscriptionEvents } = require(\"../../dist/main/index\");\nconst fetch = require(\"cross-fetch\");\n\nconst live = async () => {\n  const url = \"http://stream.live.vc.bbcmedia.co.uk/bbc_world_service\";\n\n  const deepgram = createClient(process.env.DEEPGRAM_API_KEY);\n\n  // We will collect the is_final=true messages here so we can use them when the person finishes speaking\n  let is_finals = [];\n\n  const connection = deepgram.listen.live({\n    model: \"nova-2\",\n    language: \"en-US\",\n    // Apply smart formatting to the output\n    smart_format: true,\n    // To get UtteranceEnd, the following must be set:\n    interim_results: true,\n    utterance_end_ms: 1000,\n    vad_events: true,\n    // Time in milliseconds of silence to wait for before finalizing speech\n    endpointing: 300,\n  });\n\n  connection.on(LiveTranscriptionEvents.Open, () => {\n    connection.on(LiveTranscriptionEvents.Close, () => {\n      console.log(\"Connection closed.\");\n    });\n\n    connection.on(LiveTranscriptionEvents.Metadata, (data) => {\n      console.log(`Deepgram Metadata: ${data}`);\n    });\n\n    connection.on(LiveTranscriptionEvents.Transcript, (data) => {\n      const sentence = data.channel.alternatives[0].transcript;\n\n      // Ignore empty transcripts\n      if (sentence.length == 0) {\n        return;\n      }\n      if (data.is_final) {\n        // We need to collect these and concatenate them together when we get a speech_final=true\n        // See docs: https://developers.deepgram.com/docs/understand-endpointing-interim-results\n        is_finals.push(sentence);\n\n        // Speech final means we have detected sufficent silence to consider this end of speech\n        // Speech final is the lowest latency result as it triggers as soon an the endpointing value has triggered\n        if (data.speech_final) {\n          const utterance = is_finals.join(\" \");\n          console.log(`Speech Final: ${utterance}`);\n          is_finals = [];\n        } else {\n          // These are useful if you need real time captioning and update what the Interim Results produced\n          console.log(`Is Final: ${sentence}`);\n        }\n      } else {\n        // These are useful if you need real time captioning of what is being spoken\n        console.log(`Interim Results: ${sentence}`);\n      }\n    });\n\n    connection.on(LiveTranscriptionEvents.UtteranceEnd, (data) => {\n      const utterance = is_finals.join(\" \");\n      console.log(`Deepgram UtteranceEnd: ${utterance}`);\n      is_finals = [];\n    });\n\n    connection.on(LiveTranscriptionEvents.SpeechStarted, (data) => {\n      // console.log(\"Deepgram SpeechStarted\");\n    });\n\n    connection.on(LiveTranscriptionEvents.Error, (err) => {\n      console.error(err);\n    });\n\n    fetch(url)\n      .then((r) => r.body)\n      .then((res) => {\n        res.on(\"readable\", () => {\n          connection.send(res.read());\n        });\n      });\n  });\n};\n\nlive();\n\n----\npackage.json\n{\n  \"name\": \"@deepgram/sdk\",\n  \"version\": \"0.0.0-automated\",\n  \"description\": \"Isomorphic Javascript client for Deepgram\",\n  \"keywords\": [\n    \"javascript\",\n    \"typescript\",\n    \"deepgram\",\n    \"asr\",\n    \"speech\",\n    \"sdk\"\n  ],\n  \"homepage\": \"https://github.com/deepgram/deepgram-js-sdk\",\n  \"bugs\": \"https://github.com/deepgram/deepgram-js-sdk/issues\",\n  \"license\": \"MIT\",\n  \"author\": {\n    \"name\": \"Deepgram DevRel Team\",\n    \"email\": \"devrel@deepgram.com\"\n  },\n  \"contributors\": [\n    \"Brian Barrow\",\n    \"Brian Hillis\",\n    \"Luke Oliff\",\n    \"Michael Jolley\",\n    \"Sandra Rodgers\",\n    \"Shir Goldberg\"\n  ],\n  \"files\": [\n    \"dist\",\n    \"src\"\n  ],\n  \"engines\": {\n    \"node\": \">=18.0.0\"\n  },\n  \"main\": \"dist/main/index.js\",\n  \"module\": \"dist/module/index.js\",\n  \"types\": \"dist/module/index.d.ts\",\n  \"sideEffects\": false,\n  \"repository\": \"deepgram/deepgram-js-sdk\",\n  \"scripts\": {\n    \"clean\": \"rimraf dist docs/v2\",\n    \"format\": \"prettier --write \\\"{src,test}/**/*.ts\\\"\",\n    \"build\": \"run-s clean format build:*\",\n    \"build:main\": \"tsc -p tsconfig.json\",\n    \"build:module\": \"tsc -p tsconfig.module.json\",\n    \"build:umd\": \"webpack --mode=production\",\n    \"watch\": \"nodemon -e ts --watch src --exec \\\"npm run build\\\"\",\n    \"test\": \"mocha -r ts-node/register test/*test.ts test/**/*test.ts --insect --timeout 5000 || :\",\n    \"test:coverage\": \"nyc --reporter=lcovonly --reporter=text --reporter=text-summary npm run test\",\n    \"docs\": \"typedoc --entryPoints src/index.ts --out docs/v2 --includes src/**/*.ts\",\n    \"docs:json\": \"typedoc --entryPoints src/index.ts --includes src/**/*.ts --json docs/v2/spec.json --excludeExternals\"\n  },\n  \"dependencies\": {\n    \"@deepgram/captions\": \"^1.1.1\",\n    \"@types/websocket\": \"^1.0.9\",\n    \"cross-fetch\": \"^3.1.5\",\n    \"deepmerge\": \"^4.3.1\",\n    \"events\": \"^3.3.0\",\n    \"websocket\": \"^1.0.34\"\n  },\n  \"devDependencies\": {\n    \"@commitlint/cli\": \"^17.6.7\",\n    \"@commitlint/config-conventional\": \"^17.6.7\",\n    \"@faker-js/faker\": \"^8.0.2\",\n    \"@flydotio/dockerfile\": \"^0.4.10\",\n    \"@types/chai\": \"^4.3.5\",\n    \"@types/mocha\": \"^9.1.1\",\n    \"chai\": \"^4.3.7\",\n    \"cross-env\": \"^7.0.3\",\n    \"husky\": \"^4.3.0\",\n    \"mocha\": \"^9.2.2\",\n    \"nodemon\": \"^3.0.1\",\n    \"npm-run-all\": \"^4.1.5\",\n    \"nyc\": \"^15.1.0\",\n    \"prettier\": \"^2.5.1\",\n    \"pretty-quick\": \"^3.1.3\",\n    \"rimraf\": \"^3.0.2\",\n    \"semantic-release-plugin-update-version-in-files\": \"^1.1.0\",\n    \"ts-loader\": \"^8.0.11\",\n    \"ts-node\": \"^10.9.1\",\n    \"typedoc\": \"^0.22.16\",\n    \"typescript\": \"^4.5.5\",\n    \"webpack\": \"^5.69.1\",\n    \"webpack-cli\": \"^4.9.2\"\n  },\n  \"overrides\": {\n    \"es5-ext\": \"0.10.53\"\n  },\n  \"husky\": {\n    \"hooks\": {\n      \"pre-commit\": \"pretty-quick --staged\",\n      \"commit-msg\": \"commitlint -E HUSKY_GIT_PARAMS\"\n    }\n  },\n  \"jsdelivr\": \"dist/umd/deepgram.js\",\n  \"unpkg\": \"dist/umd/deepgram.js\"\n}\n\n----\ntest\\client.test.ts\nimport { createClient } from \"../src\";\nimport { DEFAULT_URL } from \"../src/lib/constants\";\nimport { expect, assert } from \"chai\";\nimport { faker } from \"@faker-js/faker\";\nimport { stripTrailingSlash } from \"../src/lib/helpers\";\nimport DeepgramClient from \"../src/DeepgramClient\";\nimport { ListenClient } from \"../src/packages/ListenClient\";\n\nconst deepgram = createClient(faker.string.alphanumeric(40));\n\ndescribe(\"testing creation of a deepgram client object\", () => {\n  it(\"it should create the client object\", () => {\n    expect(deepgram).to.not.be.undefined;\n    expect(deepgram).is.instanceOf(DeepgramClient);\n  });\n\n  it(\"it should provide provide access to a transcription client\", () => {\n    expect(deepgram.listen).to.not.be.undefined;\n    expect(deepgram.listen).is.instanceOf(ListenClient);\n  });\n\n  it(\"it should have the default URL when no custom URL option is provided\", () => {\n    // @ts-ignore\n    const url = deepgram.baseUrl.hostname;\n\n    expect(url).to.equal(DEFAULT_URL);\n  });\n\n  it(\"it should throw an error if no valid apiKey is provided\", () => {\n    expect(() => createClient(\"\")).to.throw(\"A deepgram API key is required\");\n  });\n\n  it(\"it should throw an error if invalid options are provided\", () => {\n    expect(() => createClient(faker.string.alphanumeric(40), { global: { url: \"\" } })).to.throw(\n      `An API URL is required. It should be set to ${DEFAULT_URL} by default. No idea what happened!`\n    );\n  });\n\n  it(\"it should create the client object with a custom domain\", () => {\n    const domain = faker.internet.url({ appendSlash: false });\n    const client = createClient(faker.string.alphanumeric(40), {\n      global: { url: domain },\n    });\n\n    // @ts-ignore\n    const baseUrl = client.baseUrl;\n\n    expect(client).is.instanceOf(DeepgramClient);\n    expect(`${baseUrl.protocol}//${baseUrl.hostname}`).to.equal(domain);\n  });\n\n  it(\"it should strip trailing slashes off the API URL if they're supplied\", () => {\n    const domain = faker.internet.url({ appendSlash: true });\n    const client = createClient(faker.string.alphanumeric(40), {\n      global: { url: domain },\n    });\n\n    // @ts-ignore\n    const baseUrl = client.baseUrl;\n\n    expect(client).is.instanceOf(DeepgramClient);\n    expect(`${baseUrl.protocol}//${baseUrl.hostname}`).to.equal(stripTrailingSlash(domain));\n  });\n\n  it(\"it should still work when provided a URL without a protocol\", () => {\n    const domain = `api.mock.deepgram.com`;\n    const client = createClient(faker.string.alphanumeric(40), {\n      global: { url: domain },\n    });\n\n    // @ts-ignore\n    const url = client.baseUrl.hostname;\n\n    expect(client).is.instanceOf(DeepgramClient);\n    expect(url).to.equal(\"api.mock.deepgram.com\");\n  });\n\n  it(\"it should allow for the supply of a custom header\", () => {\n    const client = createClient(faker.string.alphanumeric(40), {\n      global: { headers: { \"X-dg-test\": \"testing\" } },\n    });\n\n    expect(client).is.instanceOf(DeepgramClient);\n  });\n\n  it(\"should use custom fetch when provided\", async () => {\n    const fetch = async () => {\n      return new Response(JSON.stringify({ customFetch: true }));\n    };\n\n    const client = createClient(faker.string.alphanumeric(40), {\n      global: { url: \"https://api.mock.deepgram.com\" },\n      _experimentalCustomFetch: fetch,\n    });\n\n    const { result, error } = await client.manage.getProjectBalances(faker.string.uuid());\n\n    assert.isNull(error);\n    assert.isNotNull(result);\n    assert.containsAllDeepKeys(result, [\"customFetch\"]);\n  });\n});\n\n----\ntest\\helpers.test.ts\nimport { expect } from \"chai\";\nimport { faker } from \"@faker-js/faker\";\nimport { applySettingDefaults, stripTrailingSlash } from \"../src/lib/helpers\";\nimport { DEFAULT_OPTIONS } from \"../src/lib/constants\";\n\ndescribe(\"testing helpers\", () => {\n  it(\"it should strip the trailing slash from a URL\", () => {\n    const URL = faker.internet.url({ appendSlash: true });\n    const expectedURL = URL.slice(0, -1);\n    expect(stripTrailingSlash(URL)).to.equal(expectedURL);\n  });\n\n  it(\"it should override defaults with options provided\", () => {\n    const options = JSON.parse(JSON.stringify(DEFAULT_OPTIONS)); // deep copy DEFAULT_OPTIONS\n    options.global.url = faker.internet.url({ appendSlash: false });\n    expect(applySettingDefaults(options, DEFAULT_OPTIONS)).to.deep.equal(options);\n  });\n});\n\n----\ntest\\live.test.ts\nimport { assert, expect } from \"chai\";\nimport { createClient } from \"../src\";\nimport { faker } from \"@faker-js/faker\";\nimport DeepgramClient from \"../src/DeepgramClient\";\nimport { LiveConnectionState, LiveTranscriptionEvents } from \"../src/lib/enums\";\n\ndescribe(\"connecting to our transcription websocket\", () => {\n  let deepgram: DeepgramClient;\n\n  beforeEach(() => {\n    deepgram = createClient(faker.string.alphanumeric(40), {\n      global: { url: \"https://api.mock.deepgram.com\" },\n    });\n  });\n\n  it(\"should create the client object\", () => {\n    expect(deepgram).to.not.be.undefined;\n    expect(deepgram).is.instanceOf(DeepgramClient);\n  });\n\n  it(\"should connect to the websocket\", function (done) {\n    const connection = deepgram.listen.live({ model: \"general\", tier: \"enhanced\" });\n\n    connection.on(LiveTranscriptionEvents.Open, (event) => {\n      expect(connection.getReadyState()).to.eq(LiveConnectionState.OPEN);\n\n      connection.on(LiveTranscriptionEvents.Metadata, (data) => {\n        assert.isNotNull(data);\n        assert.containsAllDeepKeys(data, [\"request_id\"]);\n\n        connection.finish();\n        done();\n      });\n    });\n  });\n\n  it(\"should send data and recieve a transcription object back\", function (done) {\n    const connection = deepgram.listen.live({ model: \"general\", tier: \"enhanced\" });\n\n    connection.on(LiveTranscriptionEvents.Open, () => {\n      connection.on(LiveTranscriptionEvents.Metadata, (data) => {\n        assert.isNotNull(data);\n        assert.containsAllDeepKeys(data, [\"request_id\"]);\n      });\n\n      connection.on(LiveTranscriptionEvents.Transcript, (data) => {\n        assert.isNotNull(data);\n        assert.containsAllDeepKeys(data, [\"channel\"]);\n\n        connection.finish();\n        done();\n      });\n\n      connection.send(new Uint8Array(100)); // mock ArrayBufferLike audio data\n    });\n  });\n\n  it(\"should receive a warning if trying to send zero-byte length data\", function (done) {\n    const connection = deepgram.listen.live({ model: \"general\", tier: \"enhanced\" });\n\n    connection.on(LiveTranscriptionEvents.Open, () => {\n      connection.on(LiveTranscriptionEvents.Warning, (data) => {\n        assert.isNotNull(data);\n\n        expect(data).to.eq(\n          \"Zero-byte detected, skipping. Send `CloseStream` if trying to close the connection.\"\n        );\n\n        connection.finish();\n        done();\n      });\n\n      connection.send(new Uint8Array(0));\n    });\n  });\n});\n\n--END--\n\n```\n\n\n\nD-ID docs:\n---\nOverview 📙\n===========\n\n✴️ Streams Overview\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-streams-overview)\n------------------------------------------------------------------------------------------------------------\n\n![](https://create-images-results.d-id.com/api_docs/assets/streaming_cover_v3.png)\\\nThe D-ID Live Streaming API allows you to use D-ID's AI tools to generate videos of digital humans from a single photo, in real time. This powerful functionality opens up various use cases, such as virtual assistants, interactive broadcasting, online education & training, and more. This document provides an overview of the Live Streaming API's features and guides you through the steps required to set up a video streaming session in real time. See a working example of Chat.D-ID app utilizes realtime streaming API [here](https://chat.d-id.com/)\n\n✴️ See a Working Example\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-see-a-working-example)\n----------------------------------------------------------------------------------------------------------------------\n\nChat D-ID App\\\nchat.d-id.com\n\nChat.D-ID is an interactive chatbot application that showcases the power of the D-ID Live Streaming API. It features a real-time chatbot digital human that engages in dynamic conversations with users. You can experience the power of real-time video streaming as the digital human avatar responds to your queries with personalized video messages. [Try it](https://chat.d-id.com/)\n\n![](https://create-images-results.d-id.com/api_docs/assets/sdk-streaming.jpg)Tell us what type of SDK would you choose ⭐️\\\nWe plan to release an SDK that designed to enhance our developers experience. This SDK will primarily focus on simplifying the utilization of our streaming API, while also ensuring effortless access to a wider array of features. [Vote here.](https://docs.d-id.com/page/sdk)\n\n✴️ When Not to Use Streaming\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-when-not-to-use-streaming)\n------------------------------------------------------------------------------------------------------------------------------\n\nThe Live Streaming API provides a dedicated [/talks/streams](https://docs.d-id.com/reference/createstream) endpoint specifically designed for real-time video streaming. However, if your requirement involves asynchronous video generation, where you can submit input and receive the generated video as a downloadable video file once it's ready, you should refer to the [/talks](https://docs.d-id.com/reference/createtalk) endpoint instead.\\\n![](https://create-images-results.d-id.com/api_docs/assets/when_not_to_use_streaming_v2.png)\n\n✴️ Streaming Protocol\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-streaming-protocol)\n----------------------------------------------------------------------------------------------------------------\n\nD-ID's Live Streaming protocol is based on WebRTC (Web Real-Time Communication) which is a technology that enables real-time communication, including audio, video, and data streaming, directly between web browsers or other compatible applications. It establishes a peer-to-peer connection between the participants, allowing for efficient and low-latency streaming. To learn more about WebRTC and its underlying concepts, you can visit the [WebRTC website](https://webrtc.org/). In the context of this document, we'll focus on the key aspects related to setting up a video streaming session.\n\n✴️ Terminology\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-terminology)\n--------------------------------------------------------------------------------------------------\n\nWebRTC\\\ncreate a new streamSDP Offer\\\nstart a streamICE Candidates\\\nsubmit network information\n\n![](https://create-images-results.d-id.com/api_docs/assets/webrtc.png)![](https://create-images-results.d-id.com/api_docs/assets/sdp.png)![](https://create-images-results.d-id.com/api_docs/assets/ice.png)\n\nWebRTC establishes a connection between two or more parties, allowing them to exchange audio, video, and data. This connection is peer-to-peer and is established using D-ID's signaling server.Session Description Protocol (SDP) is used to negotiate and exchange session details between peers. The initiating peer sends an SDP offer containing its capabilities, and the receiving peer responds with an SDP answer that includes its own capabilities.Interactive Connectivity Establishment (ICE) is a technique used to determine the most suitable network path between peers. ICE candidates represent possible IP addresses and transport protocols that can be used for the connection.\n\n[Create a new stream](https://docs.d-id.com/reference/createstream)[Start a stream](https://docs.d-id.com/reference/startconnection)[Submit network information](https://docs.d-id.com/reference/addicecandidate)\n\n✴️ Ready to Start\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-ready-to-start)\n--------------------------------------------------------------------------------------------------------\n\n5 Steps\\\nis all it takes\n\n![](https://create-images-results.d-id.com/api_docs/assets/5steps_v2.png)\n\n####\n\n✴️ Step 1: Create a new stream\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-step-1-create-a-new-stream)\n\nTo initiate a video streaming session, make a POST request to [/streams](https://docs.d-id.com/reference/createstream) endpoint. In the request's body, you must provide a `source_url` pointing to the photo you wish to animate in the stream. This request will provide you with a unique `id` (referred to as `stream_id` in other requests) and a session ID. The stream ID serves as a unique identifier for the streaming session, while the session ID needs to be included in subsequent requests' bodies to ensure they reach the correct server instance.\n\nHere's an example of the request you should send:\n\nJavaScript\n\n`\n\nconst sessionResponse = await fetchWithRetries(`https://api.d-id.com/talks/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic {YOUR_DID_API_KEY}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      source_url: `{AVATAR_IMAGE_URL}`,\n    }),\n  });\n\n`\n\nAnd an example of the response you would get:\n\nResponse\n\n`\n\n{\n  \"id\": \"your_stream_id\",\n  \"session_id\": \"your_session_id\",\n  \"offer\": \"your_sdp_offer\",\n  \"ice_servers\": [\n    {\n      \"urls\": [\"stun:stun.example.com\"]\n    }\n  ]\n}\n\n`\n\nMake sure to extract and store both the stream ID (`your_stream_id`) and session ID (`your_session_id`) for further usage in subsequent steps.\n\n####\n\n✴️ Step 2: Starting the stream\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-step-2-starting-the-stream)\n\nAfter receiving the SDP offer from the server in Step 1, you need to generate the SDP answer and send it back. To obtain the SDP answer, you can use WebRTC APIs or libraries that provide the necessary functionality. Here is a general outline of the steps involved:\n\n1.  Create a WebRTC peer connection object in your application.\n2.  Set the received SDP offer as the remote description of the peer connection using the `setRemoteDescription()` method.\n3.  Generate the SDP answer by calling the `createAnswer()` method on the peer connection.\n4.  Set the generated SDP answer as the local description of the peer connection using the `setLocalDescription()` method.\n\nOnce you have obtained the SDP answer as a string, you can send it back to the server using the [/talks/streams/{session_id}/sdp](https://docs.d-id.com/reference/startconnection) endpoint.\n\nHere's an example of the answer creation code, taken from [this example repository](https://github.com/de-id/live-streaming-demo):\n\nJavaScript\n\n`\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({ iceServers });\n// Here we add event listeners for any events we want to handle\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n\n  return sessionClientAnswer;\n}\n...\nconst sdpResponse = await fetch(`https://api.d-id.com/talks/streams/${streamId}/sdp`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic {YOUR_DID_API_KEY}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      answer: sessionClientAnswer,\n      session_id: sessionId,\n    }),\n  });\n};\n\n`\n\n####\n\n✴️ Step 3: Submit network information\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-step-3-submit-network-information)\n\nOnce the SDP answer is sent, you must gather ICE candidates and send them to the server to complete the WebRTC handshake. ICE candidates allow the peers to discover and establish an optimal network path for communication.\n\nListen for the `icecandidate` event on your peer connection object and send each ICE candidate to the server using the [/talks/streams/{stream_id}/ice](https://docs.d-id.com/reference/addicecandidate) endpoint. Replace `{stream_id}` with the appropriate stream ID obtained in Step 1. From the ice candidates you receive, you should only send the `candidate`, `sdpMid`, and `sdpMLineIndex` attributes.\n\nHere's an example of the `icecandidate` event handler from our streaming [demo repository](https://github.com/de-id/live-streaming-demo):\n\nJavaScript\n\n`\n\nfunction onIceCandidate(event) {\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n    fetch(`https://api.d-id.com/talks/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic {YOUR_DID_API_KEY}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        candidate,\n        sdpMid,\n        sdpMLineIndex,\n        session_id: sessionId,\n      }),\n    });\n  }\n}\n\n`\n\n####\n\nWaiting for Connection Readiness:\n\n[](https://docs.d-id.com/reference/talks-streams-overview#waiting-for-connection-readiness)\n\nAfter sending the SDP answer and the ICE candidates, you need to wait for the WebRTC connection to become ready. Listen for the `iceconnectionstatechange` event on your peer connection object and check for the `iceConnectionState` property. When the connection state changes to `connected` or `completed`, the connection is ready to proceed. This event listener is one of those we used in Step 2, specifically, `onIceConnectionStateChange`\n\n####\n\n✴️ Step 4: Create a talk stream\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-step-4-create-a-talk-stream)\n\nWith the connection established, you can now create a talk. Make a POST request to [/talks/streams/{stream_id}](https://docs.d-id.com/reference/createtalkstream) endpoint to request a video to be created and streamed over the established connection. Remember to include the session ID in the request body. In this request you can send the details of the audio or text for the avatar to speak, along with additional configuration options that allow for greater flexibility and customization.\n\n####\n\n✴️ Step 5: Closing the stream\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-step-5-closing-the-stream)\n\nTo close the video streaming session, make a DELETE request to [/talks/streams/{stream_id}](https://docs.d-id.com/reference/deletestream) endpoint. This will close the connection and end the session. If no messages are sent within the session for 5 minutes, the session will be automatically terminated.\n\nHere is an example of the request:\n\nJavaScript\n\n`\n\nfetch(`https://api.d-id.com/talks/streams/${streamId}`, {\n    method: 'DELETE',\n    headers: {\n      Authorization: `Basic {YOUR_DID_API_KEY}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ session_id: sessionId }),\n  });\n\n`\n\n✴️ Developer Starter Code\n\n[](https://docs.d-id.com/reference/talks-streams-overview#%EF%B8%8F-developer-starter-code)\n------------------------------------------------------------------------------------------------------------------------\n\nFor a code example demonstrating the entire process, you can visit the D-ID Live Streaming Demo repository. The repository provides a starter code to help you get started with implementing the D-ID Streaming API in your own applications. By following these steps, you can leverage the D-ID Live Streaming API to create engaging and interactive video streaming experiences that incorporate real-time speaking digital avatars.\n\nInitial setup:\n\n-   Clone [this repo](https://github.com/de-id/live-streaming-demo) from GitHub\n-   Install express: open a terminal in the folder and run `npm install express`\n-   Add your API key: edit the `api.json` inside the uncompressed folder and add your key there\n\nStart the example app:\n\n-   Bring up the app in the folder (ctr left click on folder through finder)\n-   Open the terminal, run `node app.js`\n-   You should see this message: `server started on port localhost:3000`\n-   Open the app in the browser, add `localhost:3000`\n-   Connect: press connect you should see the connection ready\n-   Stream: press the start button to start streaming\n\nstreaming-client-api.js:\n\n`\n'use strict';\nimport DID_API from './api.js';\n\nconst GROQ_API_KEY = DID_API.groqKey;\nconst DEEPGRAM_API_KEY = DID_API.deepgramKey;\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\nconst RTCPeerConnection = (window.RTCPeerConnection || window.webkitRTCPeerConnection || window.mozRTCPeerConnection).bind(window);\n\nlet peerConnection;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\n\n\nconst talkVideo = document.getElementById('talk-video');\ntalkVideo.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n  if (peerConnection && peerConnection.connectionState === 'connected') {\n    return;\n  }\n\n  stopAllStreams();\n  closePC();\n\n  const sessionResponse = await fetch(`${DID_API.url}/talks/streams`, {\n    method: 'POST',\n    headers: {'Authorization': `Basic ${DID_API.key}`, 'Content-Type': 'application/json'},\n    body: JSON.stringify({\n      source_url: \"https://d-id-public-bucket.s3.amazonaws.com/or-roman.jpg\"\n    }),\n  });\n\n  \n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json()\n  streamId = newStreamId;\n  sessionId = newSessionId;\n  \n  try {\n    sessionClientAnswer = await createPeerConnection(offer, iceServers);\n  } catch (e) {\n    console.log('error during streaming setup', e);\n    stopAllStreams();\n    closePC();\n    return;\n  }\n\n  const sdpResponse = await fetch(`${DID_API.url}/talks/streams/${streamId}/sdp`,\n    {\n      method: 'POST',\n      headers: {Authorization: `Basic ${DID_API.key}`, 'Content-Type': 'application/json'},\n      body: JSON.stringify({answer: sessionClientAnswer, session_id: sessionId})\n    });\n};\n\nconst talkButton = document.getElementById('talk-button');\ntalkButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') {\n    const talkResponse = await fetch(`${DID_API.url}/talks/streams/${streamId}`,\n      {\n        method: 'POST',\n        headers: { Authorization: `Basic ${DID_API.key}`, 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          'script': {\n            'type': 'audio',\n            'audio_url': 'https://d-id-public-bucket.s3.us-west-2.amazonaws.com/webrtc.mp3',\n          },\n          'driver_url': 'bank://lively/',\n          'config': {\n            'stitch': true,\n          },\n          'session_id': sessionId\n        })\n      });\n  }};\n\nconst destroyButton = document.getElementById('destroy-button');\ndestroyButton.onclick = async () => {\n  await fetch(`${DID_API.url}/talks/streams/${streamId}`,\n    {\n      method: 'DELETE',\n      headers: {Authorization: `Basic ${DID_API.key}`, 'Content-Type': 'application/json'},\n      body: JSON.stringify({session_id: sessionId})\n    });\n\n  stopAllStreams();\n  closePC();\n};\n\nfunction onIceGatheringStateChange() {\n  iceGatheringStatusLabel.innerText = peerConnection.iceGatheringState;\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n}\nfunction onIceCandidate(event) {\n  console.log('onIceCandidate', event);\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n    \n    fetch(`${DID_API.url}/talks/streams/${streamId}/ice`,\n      {\n        method: 'POST',\n        headers: {Authorization: `Basic ${DID_API.key}`, 'Content-Type': 'application/json'},\n        body: JSON.stringify({ candidate, sdpMid, sdpMLineIndex, session_id: sessionId})\n      }); \n  }\n}\nfunction onIceConnectionStateChange() {\n  iceStatusLabel.innerText = peerConnection.iceConnectionState;\n  iceStatusLabel.className = 'iceConnectionState-' + peerConnection.iceConnectionState;\n  if (peerConnection.iceConnectionState === 'failed' || peerConnection.iceConnectionState === 'closed') {\n    stopAllStreams();\n    closePC();\n  }\n}\nfunction onConnectionStateChange() {\n  // not supported in firefox\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n}\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n  signalingStatusLabel.className = 'signalingState-' + peerConnection.signalingState;\n}\nfunction onTrack(event) {\n  const remoteStream = event.streams[0];\n  setVideoElement(remoteStream);\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({iceServers});\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  console.log('set remote sdp OK');\n\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  console.log('create local sdp OK');\n\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n  console.log('set local sdp OK');\n\n  return sessionClientAnswer;\n}\n\nfunction setVideoElement(stream) {\n  if (!stream) return;\n  talkVideo.srcObject = stream;\n\n  // safari hotfix\n  if (talkVideo.paused) {\n    talkVideo.play().then(_ => {}).catch(e => {});\n  }\n}\n\nfunction stopAllStreams() {\n  if (talkVideo.srcObject) {\n    console.log('stopping video streams');\n    talkVideo.srcObject.getTracks().forEach(track => track.stop());\n    talkVideo.srcObject = null;\n  }\n}\n\nfunction closePC(pc = peerConnection) {\n  if (!pc) return;\n  console.log('stopping peer connection');\n  pc.close();\n  pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n  pc.removeEventListener('icecandidate', onIceCandidate, true);\n  pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n  }\n}\n`\n\nCreate a new stream\n===================\n\nposthttps://api.d-id.com/talks/streams\n\nInitiates the creation of a new WebRTC connection to a browser peer. The endpoint returns the necessary information to set up and manage the connection.\n\nRecent Requests\n\n| time | status | user agent |  |\n| :-- | :-- | :-- | :-- |\n|\n\nMake a request to see history.\n\n |\n\n0 Requests This Month\n\nStep 1\\\nCreate a new stream\n\n![](https://create-images-results.d-id.com/api_docs/assets/step1.png)\n\nTo initiate a video streaming session, make a POST request to this endpoint. In the request's body, you must provide a `source_url` pointing to the photo you wish to animate in the stream. This request will provide you with a unique `id` (referred to as `stream_id` in other requests) and a session ID. The stream ID serves as a unique identifier for the streaming session, while the session ID needs to be included in subsequent requests' bodies to ensure they reach the correct server instance. [Learn more](https://docs.d-id.com/reference/overview-1#-ready-to-start)\n\nBody Params\n\nsource_url\n\nstring\n\nrequired\n\nURL to a photo you wish to animate in the stream\n\ndriver_url\n\nstring\n\nThe URL of the driver video to drive the talk, or a selection from the list or provided drivers.\\\nIf not provided a driver video will be selected for you from the predefined drivers bank.\n\nface\n\nobject\n\nthe face to animate - otherwise detects the dominant face\n\nface object\n\nconfig\n\nobject\n\nAdvanced configuration options.\n\nconfig object\n\ncompatibility_mode\n\nstring\n\nDefines the video codec to be used in the stream.\\\nWhen set to on: VP8 will be used.\\\nWhen set to off: H264 will be used\\\nWhen set to auto the codec will be selected according to the browser.\n\nonoffauto\n\nstream_warmup\n\nboolean\n\nDefaults to false\n\nWhether to stream wamrup video on the connection.\\\nIf set to true, will stream a warmup video when connection is established.\\\nAt the end of the warmup video, a message containing \"stream/ready\" will be sent on the data channel.\n\ntruefalse\n\nsession_timeout\n\ndouble\n\nMaximum duration (in seconds) between messages before session times out.\\\nCan only be used with proper permissions\n\noutput_resolution\n\ndouble\n\nSupported only with Talk presenters (photo-based).\\\nThe output resolution sets the maximum height or width of the streamed video.\\\nThe aspect ratio is preserved from the source image.\\\nWhen resolution is not configured, it defaults to the agent output resolution.\n\nHeaders\n\n\n1\ncurl --request POST \\\n2\n     --url https://api.d-id.com/talks/streams \\\n3\n     --header 'accept: application/json' \\\n4\n     --header 'authorization: Basic YWRtaW4xQHNrb29wLmRpZ2l0YWw6RGp6Uzg1SzRXKlg5' \\\n5\n     --header 'content-type: application/json' \\\n6\n     --data '\n7\n{\n8\n  \"face\": {\n9\n    \"top_left\": [\n10\n      0,\n11\n      0\n12\n    ],\n13\n    \"size\": 512\n14\n  },\n15\n  \"config\": {\n16\n    \"motion_factor\": 0,\n17\n    \"align_expand_factor\": 0,\n18\n    \"stitch\": true\n19\n  },\n20\n  \"stream_warmup\": true,\n21\n  \"source_url\": \"string\",\n22\n  \"driver_url\": \"string\",\n23\n  \"compatibility_mode\": \"on\",\n24\n  \"session_timeout\": 180,\n25\n  \"output_resolution\": 512\n26\n}\n27\n'\n\n\nTry It!\nRESPONSE\n1\n{\n2\n  \"session_id\": \"string\",\n3\n  \"id\": \"string\",\n4\n  \"jsep\": {\n5\n    \"type\": \"offer\",\n6\n    \"sdp\": \"string\"\n7\n  },\n8\n  \"ice_servers\": [\n9\n    {\n10\n      \"urls\": [\n11\n        \"string\"\n12\n      ],\n13\n      \"username\": \"string\",\n14\n      \"credential\": \"string\"\n15\n    }\n16\n  ]\n17\n}\n\nStart a stream\npost\nhttps://api.d-id.com/talks/streams/{id}/sdp\nUpdates the server with the SDP answer to the SDP offer received from the initial call to the /streams endpoint, during the offer/answer negotiation of a WebRTC connection.\n\nRecent Requests\ntime\tstatus\tuser agent\t\nMake a request to see history.\n0 Requests This Month\n\nStep 2\nStart a stream\n\n\nAfter receiving the SDP offer from the server in Step 1, you need to generate the SDP answer and send it back. To obtain the SDP answer, you can use WebRTC APIs or libraries that provide the necessary functionality. Learn more\n\nPath Params\nid\nstring\nrequired\nthe stream identifier\n\nBody Params\nsession_id\nstring\nSession identifier information, should be returned in the body of all streaming requests (from the response\nof the POST /streams)\n\nanswer\nobject\nrequired\nJsep answer object used to create a peer connection\n\n\nanswer object\ntype\nstring | null\nrequired\nThe SDP contained in the sdp property is the definitive choice in the exchange. In other words, this session\ndescription describes the agreed-upon configuration, and is being sent to finalize negotiation.\n\n\nanswer\nsdp\nstring\nrequired\nDescribe the media communication sessions to accept the session the is being negotiated\n\nHeaders\n\nExample:\n\n1\ncurl --request POST \\\n2\n     --url https://api.d-id.com/talks/streams/id/sdp \\\n3\n     --header 'accept: application/json' \\\n4\n     --header 'authorization: Basic YWRtaW4xQHNrb29wLmRpZ2l0YWw6RGp6Uzg1SzRXKlg5' \\\n5\n     --header 'content-type: application/json' \\\n6\n     --data '\n7\n{\n8\n  \"session_id\": \"string\",\n9\n  \"answer\": {\n10\n    \"type\": \"answer\",\n11\n    \"sdp\": \"string\"\n12\n  }\n13\n}\n14\n'\n\n\nTry It!\nRESPONSE\n1\n{\n2\n  \"status\": \"string\"\n3\n}\n\n\nSubmit network information\npost\nhttps://api.d-id.com/talks/streams/{id}/ice\nUpdates the server with a WebRTC ICE candidate. If the candidate parameter is missing or a value of null is given the added ICE candidate is an \"end-of-candidates\" indicator.\n\nRecent Requests\ntime\tstatus\tuser agent\t\nMake a request to see history.\n0 Requests This Month\n\nStep 3\nSubmit network information\n\n\nOnce the SDP answer is sent, you must gather ICE candidates and send them to the server to complete the WebRTC handshake. ICE candidates allow the peers to discover and establish an optimal network path for communication. Listen for the icecandidate event on your peer connection object and send each ICE candidate to the server using this endpoint. Replace {stream_id} with the appropriate stream ID obtained in Step 1. From the ice candidates you receive, you should only send the candidate, sdpMid, and sdpMLineIndex attributes. Learn more\n\nPath Params\nid\nstring\nrequired\nthe stream identifier\n\nBody Params\n\nIceCandidate\ncandidate\nstring\nrequired\nA string representing the transport address for the candidate that can be used for connectivity checks.\nThe format of this address is a candidate-attribute as defined in RFC 5245. This string is empty (\"\") if the\nRTCIceCandidate is an \"end of candidates\" indicator.\n\nsdpMid\nstring\nrequired\nA string specifying the candidate's media stream identification tag which uniquely identifies the media stream\nwithin the component with which the candidate is associated, or null if no such association exists.\n\nsdpMLineIndex\ndouble\nrequired\nIf not null, sdpMLineIndex indicates the zero-based index number of the media description (as defined in RFC\n4566) in the SDP with which the candidate is associated.\n\nsession_id\nstring\nSession identifier information, should be returned in the body of all streaming requests (from the response\nof the POST /streams)\n\n\nOption 2\nHeaders\n\nsession_id\nstring\nSession identifier information, should be returned in the body of all streaming requests (from the response\nof the POST /streams)\n\nexample:\n\n1\ncurl --request POST \\\n2\n     --url https://api.d-id.com/talks/streams/id/ice \\\n3\n     --header 'accept: application/json' \\\n4\n     --header 'authorization: Basic YWRtaW4xQHNrb29wLmRpZ2l0YWw6RGp6Uzg1SzRXKlg5' \\\n5\n     --header 'content-type: application/json' \\\n6\n     --data '\n7\n{\n8\n  \"candidate\": \"string\",\n9\n  \"sdpMid\": \"string\",\n10\n  \"sdpMLineIndex\": 0\n11\n}\n12\n'\n\n\nTry It!\nRESPONSE\n1\n{\n2\n  \"status\": \"string\"\n3\n}\n\n\nCreate a talk stream\n====================\n\nposthttps://api.d-id.com/talks/streams/{id}\n\nRecent Requests\n\n| time | status | user agent |  |\n| :-- | :-- | :-- | :-- |\n|\n\nMake a request to see history.\n\n |\n\n0 Requests This Month\n\nStep 4\\\nCreate a talk stream\n\n![](https://create-images-results.d-id.com/api_docs/assets/step4.png)\n\nWith the connection established, you can now create a talk. Make a POST request to this endpoint to request a video to be created and streamed over the established connection. Remember to include the session ID in the request body. In this request you can send the details of the audio or text for the avatar to speak, along with additional configuration options that allow for greater flexibility and customization. [Learn more](https://docs.d-id.com/reference/overview-1#-ready-to-start)\n\nPath Params\n\nid\n\nstring\n\nrequired\n\nthe stream identifier\n\nBody Params\n\nsession_id\n\nstring\n\nresult_url\n\nstring\n\nThe URL to save the video result.\n\nscript\n\nrequired\n\nStream_Text_Script\n\ntype\n\nstring | null\n\nrequired\n\nThe type of the script.\n\ntext\n\nprovider\n\ntext-to-speech provider from list of supported providers. default is microsoft tts\n\nMicrosoft_tts_provider1\n\nAzureMicrosoft provider details, contains the provider type and requested voice id and style\n\ntype\n\nstring\n\nrequired\n\nmicrosoft\n\nvoice_id\n\nstring\n\nrequired\n\nDefaults to en-US-JennyNeural\n\nThe voice_id from the list of available voices.\\\nFor full list of voice_ids: <https://docs.d-id.com/reference/microsoft-azure>\n\nvoice_config\n\nobject\n\nVoice customization options\n\nvoice_config object\n\nlanguage\n\nstring\n\nVoice customization options. To save the language of the selected agent voice\n\nElevenlabs_stream_tts_provider1\n\ninput\n\nstring\n\nrequired\n\nThe input text that will be synthesized to an audio file.\\\nNote that each provider has its own limitations on the text length.\n\nssml\n\nboolean\n\nDefaults to false\n\nIs the text provided in ssml form.\n\ntruefalse\n\nStream_Audio_Script\n\nStream_LLM_Script\n\nconfig\n\nobject\n\nConstruct a type with the properties of T except for those in type K.\n\nconfig object\n\nuser_data\n\nstring\n\nNon-sensitive custom data that will be added to the talk response and webhook.\n\nname\n\nstring\n\nThe name of the talk video\n\naudio_optimization\n\ndouble\n\nDefaults to 2\n\nThe optimization level of the audio\n\nmetadata\n\nstring\n\nMetadata passed to the talks worker\n\nShow Deprecated\n\nHeaders\n\nx-api-key-external\n\nstring\n\nIt is possible to add external API key for TTS generation, to access the API programmatically. The x-api-key-external header must be added, the required value format is {\"elevenlabs\": \"your-api-key\"}. Note: Your ElevenLabs quota consumes. Example: x-api-key-external: \"{\"elevenlabs\": \"ABCDEFGH123456\"}\"\n\nShow Deprecated\n\nexample:\nCreate a talk stream\n====================\n\nposthttps://api.d-id.com/talks/streams/{id}\n\nRecent Requests\n\n| time | status | user agent |  |\n| :-- | :-- | :-- | :-- |\n|\n\nMake a request to see history.\n\n |\n\n0 Requests This Month\n\nStep 4\\\nCreate a talk stream\n\n![](https://create-images-results.d-id.com/api_docs/assets/step4.png)\n\nWith the connection established, you can now create a talk. Make a POST request to this endpoint to request a video to be created and streamed over the established connection. Remember to include the session ID in the request body. In this request you can send the details of the audio or text for the avatar to speak, along with additional configuration options that allow for greater flexibility and customization. [Learn more](https://docs.d-id.com/reference/overview-1#-ready-to-start)\n\nPath Params\n\nid\n\nstring\n\nrequired\n\nthe stream identifier\n\nBody Params\n\nsession_id\n\nstring\n\nresult_url\n\nstring\n\nThe URL to save the video result.\n\nscript\n\nrequired\n\nStream_Text_Script\n\ntype\n\nstring | null\n\nrequired\n\nThe type of the script.\n\ntext\n\nprovider\n\ntext-to-speech provider from list of supported providers. default is microsoft tts\n\nMicrosoft_tts_provider1\n\nAzureMicrosoft provider details, contains the provider type and requested voice id and style\n\ntype\n\nstring\n\nrequired\n\nmicrosoft\n\nvoice_id\n\nstring\n\nrequired\n\nDefaults to en-US-JennyNeural\n\nThe voice_id from the list of available voices.\\\nFor full list of voice_ids: <https://docs.d-id.com/reference/microsoft-azure>\n\nvoice_config\n\nobject\n\nVoice customization options\n\nvoice_config object\n\nlanguage\n\nstring\n\nVoice customization options. To save the language of the selected agent voice\n\nElevenlabs_stream_tts_provider1\n\ninput\n\nstring\n\nrequired\n\nThe input text that will be synthesized to an audio file.\\\nNote that each provider has its own limitations on the text length.\n\nssml\n\nboolean\n\nDefaults to false\n\nIs the text provided in ssml form.\n\ntruefalse\n\nStream_Audio_Script\n\nStream_LLM_Script\n\nconfig\n\nobject\n\nConstruct a type with the properties of T except for those in type K.\n\nconfig object\n\nuser_data\n\nstring\n\nNon-sensitive custom data that will be added to the talk response and webhook.\n\nname\n\nstring\n\nThe name of the talk video\n\naudio_optimization\n\ndouble\n\nDefaults to 2\n\nThe optimization level of the audio\n\nmetadata\n\nstring\n\nMetadata passed to the talks worker\n\nShow Deprecated\n\nHeaders\n\nx-api-key-external\n\nstring\n\nIt is possible to add external API key for TTS generation, to access the API programmatically. The x-api-key-external header must be added, the required value format is {\"elevenlabs\": \"your-api-key\"}. Note: Your ElevenLabs quota consumes. Example: x-api-key-external: \"{\"elevenlabs\": \"ABCDEFGH123456\"}\"\n\nShow Deprecated\n---\n\n\n\n\n\n\nRepo:\n---\n\nThe following text is a Git repository with code. The structure of the text are sections that begin with ----, followed by a single line containing the file path and file name, followed by a variable amount of lines containing the file contents. The text representing the Git repository ends when the symbols --END-- are encounted. Any further text beyond --END-- are meant to be interpreted as instructions using the aforementioned Git repository as context.\n----\nREADME.md\n# Streaming Live Demo by D-ID\n\n* (install express) Open a terminal in the folder and run - `npm install express`\n* (add your API key) Edit the `api.json` inside the uncompressed folder and replace the emoji with your key\n* (select service) in the same `api.json` file, edit the `service` field to choose your avatar type, use `talks` for an avatar made from an image or `clips` to use a premade HQ avatar from a video\n\n## Start Streaming Demo:\n* (bring up the app) in the folder (ctr left click on folder through finder) open the terminal run `node app.js`\n* you should see this message - server started on port localhost:3000\n* (open the app) In the browser add localhost:3000\n* (connect) press connect you should see the connection ready \n* (stream) Press the start button to start streaming\n<img src=\"./app.png\" alt=\"Streaming App\" width=\"200\"/>\n\n## ⭐ Start Agents Demo [NEW!] ⭐\n* (bring up the app) in the folder (ctr left click on folder through finder) open the terminal `run node app.js` \n* you should see this message - server started on port localhost:3000\n* (open the app) In the browser add localhost:3000/agents\n* press 'Create new Agent with Knowledge' to create a new Agent. All API endpoints' responses are visible in the console. \n* press 'Connect' to connect to the agent, once done, type a message and press 'Send' to start a chat\n* you can store the created `agentId` and `chatID` variables and at the bottom of the `agents-client-api.js` file for future chats with your newly created Agent.\n![app](./agents_app.png)\n\n----\nagents-client-api.js\n\n'use strict';\nimport DID_API from './api.js';\n\nconst DEEPGRAM_API_KEY = DID_API.deepgramKey;\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.js and restart..');\n\nconst RTCPeerConnection = (\n  window.RTCPeerConnection ||\n  window.webkitRTCPeerConnection ||\n  window.mozRTCPeerConnection\n).bind(window);\n\nlet peerConnection;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet chatHistory = [];\nlet mediaRecorder;\nlet deepgramSocket;\nlet transcript = '';\nlet inactivityTimeout;\nlet transcriptionTimer;\n\nconst context = `You are a helpful, harmless, and honest assistant. Please answer the users questions briefly, be concise, not more than 1 sentence unless absolutely needed.`;\n\nconst videoElement = document.getElementById('video-element');\nvideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\n\nwindow.onload = async (event) => {\n  initializeIdleVideo();\n  showLoadingSymbol();\n  try {\n    await connectButton.onclick();\n    hideLoadingSymbol();\n  } catch (error) {\n    console.error('Error during auto-initialization:', error);\n    hideLoadingSymbol();\n    showErrorMessage('Failed to connect. Please try again.');\n  }\n};\n\n\nfunction initializeIdleVideo() {\n  videoElement.src = 'emma_idle.mp4';\n  videoElement.loop = true;\n  videoElement.muted = true; // Mute the video to allow autoplay\n  videoElement.playsInline = true;\n  \n  // Attempt to play the video\n  videoElement.play().catch(error => {\n    console.warn(\"Autoplay was prevented for idle video:\", error);\n    // If autoplay is prevented, we'll show a play button\n    showPlayButton();\n  });\n}\n\nfunction playIdleVideo() {\n  if (videoElement.src !== 'emma_idle.mp4') {\n    videoElement.src = 'emma_idle.mp4';\n  }\n  videoElement.loop = true;\n  videoElement.muted = true; // Ensure it's muted for autoplay\n  videoElement.currentTime = 0; // Reset to the beginning\n  \n  videoElement.play().catch(error => {\n    console.warn(\"Playback of idle video was prevented:\", error);\n    // If play is prevented, we'll show a play button\n    showPlayButton();\n  });\n}\n\nfunction showPlayButton() {\n  const playButton = document.createElement('button');\n  playButton.textContent = 'Play Idle Video';\n  playButton.style.position = 'absolute';\n  playButton.style.zIndex = '1000';\n  playButton.style.top = '50%';\n  playButton.style.left = '50%';\n  playButton.style.transform = 'translate(-50%, -50%)';\n  playButton.onclick = () => {\n    videoElement.play();\n    playButton.remove();\n  };\n  videoElement.parentElement.appendChild(playButton);\n}\n\nfunction setVideoElement(stream) {\n  if (!stream) {\n    console.log('No stream available to set video element');\n    playIdleVideo();\n    return;\n  }\n\n  videoElement.srcObject = stream;\n  videoElement.muted = false; // Unmute for the actual conversation\n  videoElement.loop = false;\n\n  videoElement.play().then(() => {\n    console.log('Video playback started');\n  }).catch(e => {\n    console.error('Error playing video:', e);\n    // If autoplay is prevented for the stream, show a play button\n    showPlayButton();\n  });\n}\n\n\nfunction showLoadingSymbol() {\n  const loadingSymbol = document.createElement('div');\n  loadingSymbol.id = 'loading-symbol';\n  loadingSymbol.innerHTML = 'Connecting...';\n  loadingSymbol.style.position = 'absolute';\n  loadingSymbol.style.top = '50%';\n  loadingSymbol.style.left = '50%';\n  loadingSymbol.style.transform = 'translate(-50%, -50%)';\n  loadingSymbol.style.backgroundColor = 'rgba(0, 0, 0, 0.8)';\n  loadingSymbol.style.color = 'white';\n  loadingSymbol.style.padding = '10px';\n  loadingSymbol.style.borderRadius = '5px';\n  loadingSymbol.style.zIndex = '9999';\n  document.body.appendChild(loadingSymbol);\n}\n\nfunction hideLoadingSymbol() {\n  const loadingSymbol = document.getElementById('loading-symbol');\n  if (loadingSymbol) {\n    document.body.removeChild(loadingSymbol);\n  }\n}\n\nfunction showErrorMessage(message) {\n  const errorMessage = document.createElement('div');\n  errorMessage.innerHTML = message;\n  errorMessage.style.color = 'red';\n  errorMessage.style.marginBottom = '10px';\n  document.body.appendChild(errorMessage);\n\n  destroyButton.style.display = 'inline-block';\n  connectButton.style.display = 'inline-block';\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    const config = {\n      iceServers,\n      sdpSemantics: 'unified-plan'\n    };\n    peerConnection = new RTCPeerConnection(config);\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n\n    // Add transceivers for both audio and video\n    peerConnection.addTransceiver('audio', {direction: 'recvonly'});\n    peerConnection.addTransceiver('video', {direction: 'recvonly'});\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  console.log('set remote sdp OK');\n\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  console.log('create local sdp OK');\n\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n  console.log('set local sdp OK');\n\n  return sessionClientAnswer;\n}\n\nfunction onIceGatheringStateChange() {\n  iceGatheringStatusLabel.innerText = peerConnection.iceGatheringState;\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n}\n\nfunction onIceCandidate(event) {\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        candidate,\n        sdpMid,\n        sdpMLineIndex,\n        session_id: sessionId,\n      }),\n    });\n  }\n}\n\nfunction onIceConnectionStateChange() {\n  iceStatusLabel.innerText = peerConnection.iceConnectionState;\n  iceStatusLabel.className = 'iceConnectionState-' + peerConnection.iceConnectionState;\n\n  if (peerConnection.iceConnectionState === 'failed' || peerConnection.iceConnectionState === 'closed') {\n    stopAllStreams();\n    closePC();\n    showErrorMessage('Connection lost. Please try again.');\n  }\n}\n\nfunction onConnectionStateChange() {\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n}\n\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n  signalingStatusLabel.className = 'signalingState-' + peerConnection.signalingState;\n}\n\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n  if (videoIsPlaying) {\n    status = 'streaming';\n    setVideoElement(stream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n  }\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n}\n\n\n\nfunction onTrack(event) {\n  console.log('onTrack event:', event);\n  if (!event.track) return;\n\n  if (statsIntervalId) {\n    clearInterval(statsIntervalId);\n  }\n\n  statsIntervalId = setInterval(async () => {\n    if (peerConnection && peerConnection.connectionState === 'connected') {\n      try {\n        const stats = await peerConnection.getStats(event.track);\n        stats.forEach((report) => {\n          if (report.type === 'inbound-rtp' && report.mediaType === 'video') {\n            const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n            if (videoStatusChanged) {\n              videoIsPlaying = report.bytesReceived > lastBytesReceived;\n              onVideoStatusChange(videoIsPlaying, event.streams[0]);\n            }\n            lastBytesReceived = report.bytesReceived;\n          }\n        });\n      } catch (error) {\n        console.error('Error getting stats:', error);\n      }\n    } else {\n      console.log('Peer connection not ready for stats.');\n    }\n  }, 1000);\n\n  setVideoElement(event.streams[0]);\n}\n\nfunction setVideoElement(stream) {\n  if (!stream) {\n    console.log('No stream available to set video element');\n    return;\n  }\n\n  videoElement.srcObject = stream;\n  videoElement.muted = false; // Unmute for response videos\n  videoElement.classList.add(\"animated\");\n\n  videoElement.play().then(() => {\n    console.log('Video playback started');\n  }).catch(e => {\n    console.error('Error playing video:', e);\n    // Fallback to idle video if there's an error\n    playIdleVideo();\n  });\n\n  // Remove Animation Class after it's completed\n  setTimeout(() => {\n    videoElement.classList.remove(\"animated\");\n  }, 300);\n}\n\n\n\nfunction playIdleVideo() {\n  videoElement.srcObject = undefined;\n  videoElement.src = 'emma_idle.mp4';\n  videoElement.loop = true;\n  videoElement.muted = true; // Mute the idle video\n  videoElement.play().then(() => {\n    console.log('Idle video playback started');\n  }).catch(e => console.error('Error playing idle video:', e));\n}\n\n\n\nfunction stopAllStreams() {\n  if (videoElement.srcObject) {\n    console.log('stopping video streams');\n    videoElement.srcObject.getTracks().forEach((track) => track.stop());\n    videoElement.srcObject = null;\n  }\n}\n\nfunction closePC(pc = peerConnection) {\n  if (!pc) return;\n  console.log('stopping peer connection');\n  pc.close();\n  pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n  pc.removeEventListener('icecandidate', onIceCandidate, true);\n  pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  clearInterval(statsIntervalId);\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n  }\n}\n\nconst maxRetryCount = 2;\nconst maxDelaySec = 2;\nasync function fetchWithRetries(url, options, retries = 1) {\n  try {\n    return await fetch(url, options);\n  } catch (err) {\n    if (retries <= maxRetryCount) {\n      const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 500;\n      await new Promise((resolve) => setTimeout(resolve, delay));\n      console.log(`Request failed, retrying ${retries}/${maxRetryCount}. Error ${err}`);\n      return fetchWithRetries(url, options, retries + 1);\n    } else {\n      throw new Error(`Max retries exceeded. error: ${err}`);\n    }\n  }\n}\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n  if (peerConnection && peerConnection.connectionState === 'connected') {\n    return;\n  }\n  stopAllStreams();\n  closePC();\n\n  const sessionResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      source_url: 'https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg',\n      compatibility_mode: 'auto',\n      output_resolution: 720,\n      stream_warmup: true\n    }),\n  });\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n  streamId = newStreamId;\n  sessionId = newSessionId;\n  try {\n    sessionClientAnswer = await createPeerConnection(offer, iceServers);\n  } catch (e) {\n    console.log('error during streaming setup', e);\n    stopAllStreams();\n    closePC();\n    return;\n  }\n\n  const sdpResponse = await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/sdp`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      answer: sessionClientAnswer,\n      session_id: sessionId,\n    }),\n  });\n};\n\nasync function startStreaming(assistantReply) {\n  try {\n    const playResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        script: {\n          type: 'text',\n          input: assistantReply,\n          provider: {\n            type: 'microsoft',\n            voice_id: 'en-US-JennyMultilingualV2Neural'\n          }\n        },\n        config: {\n          fluent: true,\n          pad_audio: 0,\n          stitch: true\n        },\n        session_id: sessionId,\n      }),\n    });\n\n    // Ensure video is unmuted when streaming starts\n    videoElement.muted = false;\n  } catch (error) {\n    console.error('Error during streaming:', error);\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  }\n}\n\n\nasync function startRecording() {\n  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n  mediaRecorder = new MediaRecorder(stream);\n\n  deepgramSocket = new WebSocket('wss://api.deepgram.com/v1/listen', [\n    'token',\n    DEEPGRAM_API_KEY,\n  ]);\n\n  deepgramSocket.onopen = () => {\n    console.log('Connection opened');\n    mediaRecorder.addEventListener('dataavailable', async (event) => {\n      if (event.data.size > 0 && deepgramSocket.readyState === 1) {\n        deepgramSocket.send(event.data);\n      }\n    });\n    mediaRecorder.start(1000);\n\n    setInterval(() => {\n      if (deepgramSocket.readyState === 1) {\n        const keepAliveMsg = JSON.stringify({ type: \"KeepAlive\" });\n        deepgramSocket.send(keepAliveMsg);\n        console.log(\"Sent KeepAlive message\");\n      }\n    }, 3000);\n\n    transcriptionTimer = setInterval(() => {\n      if (transcript.trim() !== '') {\n        document.getElementById('msgHistory').innerHTML += `<span style='opacity:0.5'><u>User:</u> ${transcript}</span><br>`;\n        chatHistory.push({\n          role: 'user',\n          content: transcript,\n        });\n        sendChatToGroq();\n        transcript = '';\n      }\n    }, 3000);\n  };\n\n  deepgramSocket.onmessage = (message) => {\n    const received = JSON.parse(message.data);\n    const partialTranscript = received.channel.alternatives[0].transcript;\n\n    if (partialTranscript) {\n      transcript += partialTranscript;\n      document.getElementById('msgHistory').innerHTML = document.getElementById('msgHistory').innerHTML.replace(/<span style='opacity:0.5'><u>User \\(interim\\):<\\/u>.*<\\/span><br>/, `<span style='opacity:0.5'><u>User (interim):</u> ${transcript}</span><br>`);\n    }\n  };\n\n  deepgramSocket.onclose = async () => {\n    console.log('WebSocket connection closed');\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  };\n\n  // Start inactivity timeout\n  inactivityTimeout = setTimeout(() => {\n    if (isRecording) {\n      console.log('Inactivity timeout reached. Stopping recording.');\n      startButton.click();\n    }\n  }, 45000); // 45 seconds\n}\n\nasync function stopRecording() {\n  if (mediaRecorder && mediaRecorder.state === 'recording') {\n    mediaRecorder.stop();\n    const closeMsg = JSON.stringify({ type: \"CloseStream\" });\n    deepgramSocket.send(closeMsg);\n    deepgramSocket.close();\n    mediaRecorder = null;\n  }\n\n  // Clear transcription timer\n  clearInterval(transcriptionTimer);\n\n  // Clear inactivity timeout\n  clearTimeout(inactivityTimeout);\n}\n\nasync function sendChatToGroq() {\n  try {\n    const response = await fetch('https://avatar.skoop.digital/chat', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        messages: [\n          {\n            role: 'system',\n            content: context,\n          },\n          ...chatHistory,\n        ],\n        model: 'mixtral-8x7b-32768',\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error ${response.status}`);\n    }\n\n    const reader = response.body.getReader();\n    let assistantReply = '';\n    let done = false;\n\n    while (!done) {\n      const { value, done: readerDone } = await reader.read();\n      done = readerDone;\n\n      if (value) {\n        const chunk = new TextDecoder().decode(value);\n        const lines = chunk.split('\\n');\n\n        for (const line of lines) {\n          if (line.startsWith('data:')) {\n            const data = line.substring(5).trim();\n            if (data === '[DONE]') {\n              done = true;\n              break;\n            }\n\n            const parsed = JSON.parse(data);\n            assistantReply += parsed.choices[0]?.delta?.content || '';\n          }\n        }\n      }\n    }\n\n    // Add assistant reply to chat history\n    chatHistory.push({\n      role: 'assistant',\n      content: assistantReply,\n    });\n\n    // Append the complete assistant reply to the chat history element\n    document.getElementById('msgHistory').innerHTML += `<span><u>Assistant:</u> ${assistantReply}</span><br>`;\n\n    // Reset inactivity timeout\n    clearTimeout(inactivityTimeout);\n    inactivityTimeout = setTimeout(() => {\n      if (isRecording) {\n        console.log('Inactivity timeout reached. Stopping recording.');\n        startButton.click();\n      }\n    }, 45000); // 45 seconds\n\n    // Initiate streaming\n    await startStreaming(assistantReply);\n  } catch (error) {\n    console.error('Error:', error);\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  }\n}\n\nasync function reinitializeConnection() {\n  console.log('Reinitializing connection...');\n  stopAllStreams();\n  closePC();\n\n  // Clear transcription timer\n  clearInterval(transcriptionTimer);\n\n  // Clear inactivity timeout\n  clearTimeout(inactivityTimeout);\n\n  // Reset transcription state\n  transcript = '';\n  chatHistory = chatHistory.slice(0, -1); // Remove the last incomplete transcription from the chat history\n\n  // Update UI to remove the incomplete transcription\n  const msgHistory = document.getElementById('msgHistory');\n  msgHistory.innerHTML = msgHistory.innerHTML.slice(0, msgHistory.innerHTML.lastIndexOf('<span style=\\'opacity:0.5\\'><u>User:</u>'));\n\n  await connectButton.onclick();\n  await startRecording();\n}\n\nconst destroyButton = document.getElementById('destroy-button');\ndestroyButton.onclick = async () => {\n  await fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n    method: 'DELETE',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ session_id: sessionId }),\n  });\n\n  stopAllStreams();\n  closePC();\n};\n\nconst startButton = document.getElementById('start-button');\nlet isRecording = false;\n\nstartButton.onclick = async () => {\n  if (!isRecording) {\n    startButton.textContent = 'Stop';\n    await startRecording();\n  } else {\n    startButton.textContent = 'Speak';\n    await stopRecording();\n  }\n  isRecording = !isRecording;\n};\n----\napi.js\nexport default {\n    key: \"YWRtaW4xQHNrb29wLmRpZ2l0YWw:1FItMzMiqjms0QwfA9g8p\",\n    url: \"https://api.d-id.com\",\n    service: \"talks\",\n    groqKey: \"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\",\n    deepgramKey: \"ab184815a3899aea7e3add69b9d5b7bc6894dc74\"\n};\n----\napp.js\nconst express = require('express');\nconst http = require('http');\nconst cors = require('cors');\n\nconst port = 3000;\n\nconst app = express();\napp.use(cors());\n\napp.use('/', express.static(__dirname, {\n    setHeaders: (res, path) => {\n      if (path.endsWith('.json')) {\n        res.type('application/javascript');\n      }\n    }\n  }));\n\napp.use('/', express.static(__dirname));\n\napp.get('/', function(req, res) {\n    res.sendFile(__dirname + '/index.html')\n});\napp.get('/agents', function(req, res) {\n    res.sendFile(__dirname + '/index-agents.html')\n});\n\nconst server = http.createServer(app);\n\nserver.listen(port, () => console.log(`Server started on port localhost:${port}`));\n\n\n----\ngroqServer.js\nconst express = require('express');\nconst cors = require('cors');\nconst Groq = require('groq-sdk');\n\nconst app = express();\nconst port = 3001;\n\nconst GROQ_API_KEY = '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';\nconst groq = new Groq({ apiKey: GROQ_API_KEY });\n\napp.use(cors());\napp.use(express.json());;\n\napp.post('/chat', async (req, res) => {\n  const { messages, model } = req.body;\n\n  try {\n    const completion = await groq.chat.completions.create({\n      messages,\n      model,\n      stream: true,\n    });\n\n    res.writeHead(200, {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache',\n      Connection: 'keep-alive',\n    });\n\n    for await (const chunk of completion) {\n      res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\n    }\n\n    res.write(`data: [DONE]\\n\\n`);\n    res.end();\n  } catch (error) {\n    console.error('Error:', error);\n    res.status(500).json({ error: 'An error occurred' });\n  }\n});\n\napp.listen(port, () => {\n  console.log(`Server is running on port ${port}`);\n});\n----\nindex-agents.html\n<!DOCTYPE html>\n<html>\n\n<head>\n  <title>D-ID Agents API Demo</title>\n  <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n  <link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\" rel=\"stylesheet\" />\n  <link rel=\"stylesheet\" href=\"style-agents.css\">\n  <link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://studio.d-id.com/favicon/favicon-192x192.png\">\n</head>\n\n<body>\n  <div id=\"content\">\n    <div id=\"status\">\n      <h4>WebRTC Connection Status</h4>\n      ICE gathering status: <label id=\"ice-gathering-status-label\"></label><br />\n      ICE status: <label id=\"ice-status-label\"></label><br />\n      Peer connection status: <label id=\"peer-status-label\"></label><br />\n      Signaling status: <label id=\"signaling-status-label\"></label><br />\n      Streaming status: <label id=\"streaming-status-label\"></label><br />\n      <br>\n      <div id=\"buttons\">\n        <button id=\"connect-button\" type=\"button\">Connect</button>\n        <button id=\"destroy-button\" type=\"button\">Destroy</button>\n      </div>\n    </div>\n\n    <div id=\"video-wrapper\">\n      <div>\n        <video id=\"video-element\" width=\"400\" height=\"400\" src=\"\" autoplay loop muted class=\"animated\"></video>\n      </div>\n    </div>\n\n    <div class=\"chat\">\n      <h4>Chat History</h4>\n      <div id=\"msgHistory\">\n      </div>\n    </div>\n  </div>\n\n\n\n  </div>\n  <div>\n    <h3>Click the button below to start speaking:</h3>\n <button id=\"start-button\"\n      type=\"button\">Speak</button>\n  </div>\n\n  <script type=\"module\" src=\"./agents-client-api.js\"></script>\n</body>\n\n</html>\n----\nindex-agents.js\nimport './agents-client-api.js';\n\n----\nindex.html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>D-ID Streaming POC</title>\n    <!-- added google fonts -->\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n    <link\n      href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\"\n      rel=\"stylesheet\"\n    />\n\n    <style>\n      .peerConnectionState-new {\n        color: cornflowerblue;\n      }\n      .peerConnectionState-connecting {\n        color: orange;\n      }\n      .peerConnectionState-connected {\n        color: green;\n      }\n      .peerConnectionState-disconnected,\n      .peerConnectionState-closed,\n      .peerConnectionState-failed {\n        color: red;\n      }\n\n      .iceConnectionState-new {\n        color: cornflowerblue;\n      }\n      .iceConnectionState-checking {\n        color: orange;\n      }\n      .iceConnectionState-connected,\n      .iceConnectionState-completed {\n        color: green;\n      }\n      .peerConnectionState-disconnected,\n      .peerConnectionState-closed,\n      .peerConnectionState-failed {\n        color: red;\n      }\n\n      .iceGatheringState-new {\n        color: cornflowerblue;\n      }\n      .iceGatheringState-gathering {\n        color: orange;\n      }\n      .iceGatheringState-complete {\n        color: black;\n      }\n\n      .signalingState-stable {\n        color: green;\n      }\n      .signalingState-have-local-offer,\n      .signalingState-have-remote-offer,\n      .signalingState-have-local-pranswer,\n      .signalingState-have-remote-pranswer {\n        color: cornflowerblue;\n      }\n      .signalingState-closed {\n        color: red;\n      }\n\n      .streamingState-streaming {\n        color: green;\n      }\n\n      .streamingState-empty {\n        color: grey;\n      }\n\n      /* added css from here */\n\n      body * {\n        font-family: 'Mulish', sans-serif;\n        text-align: center;\n      }\n\n      #content {\n        width: 820px;\n        position: relative;\n        margin: 0 auto;\n      }\n\n      #buttons {\n        clear: both;\n        padding: 0 0 0 0;\n        text-align: center;\n      }\n\n      button {\n        padding: 10px 20px;\n        border-radius: 5px;\n        border: none;\n        font-size: 16px;\n        margin: 0 5px;\n        background-color: #7459fe;\n        color: #fff;\n      }\n\n      button:hover {\n        background-color: #9480ff;\n        cursor: pointer;\n        transition: all 0.2s ease-out;\n      }\n\n      #status {\n        clear: both;\n        padding: 20px 0 0 0;\n        text-align: left;\n        display: inline-block;\n        zoom: 1;\n        line-height: 140%;\n        font-size: 15px;\n      }\n\n      #status div {\n        padding-bottom: 10px;\n      }\n\n      #video-wrapper {\n        background: url(bg.png);\n        height: 500px;\n        background-position: top;\n      }\n\n      #video-wrapper div {\n        width: 400px;\n        margin: 0 auto;\n        padding: 50px 0 0 0;\n      }\n      video {\n        display: block;\n        /*border:1px solid;*/\n        border-radius: 50%;\n        background-color: #fff;\n      }\n    </style>\n  </head>\n\n  <body>\n    <!-- adde \"id=content\" -->\n    <div id=\"content\">\n      <!-- added \"id=video-wrapper\" -->\n      <div id=\"video-wrapper\">\n        <div>\n          <video id=\"video-element\" width=\"400\" height=\"400\" autoplay></video>\n        </div>\n      </div>\n      <br />\n\n      <!-- added div#buttons -->\n      <div id=\"buttons\">\n        <button id=\"connect-button\" type=\"button\">Connect</button>\n        <button id=\"start-button\" type=\"button\">Start</button>\n        <button id=\"destroy-button\" type=\"button\">Destroy</button>\n      </div>\n\n      <!-- added div#status -->\n      <div id=\"status\">\n        <!-- removed the wrapping <div> tags -->\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label\n        ><br />\n        ICE status: <label id=\"ice-status-label\"></label><br />\n        Peer connection status: <label id=\"peer-status-label\"></label><br />\n        Signaling status: <label id=\"signaling-status-label\"></label><br />\n        Streaming status: <label id=\"streaming-status-label\"></label><br />\n      </div>\n    </div>\n\n    <script type=\"module\" src=\"./index.js\"></script>\n  </body>\n</html>\n\n----\nindex.js\nimport './streaming-client-api.js';\n\n----\npackage.json\n{\n  \"dependencies\": {\n    \"cors\": \"^2.8.5\",\n    \"express\": \"^4.18.2\",\n    \"groq-sdk\": \"^0.5.0\"\n  },\n  \"scripts\": {\n    \"dev\": \"node app.js\"\n  }\n}\n----\nstyle-agents.css\n.peerConnectionState-new {\n  color: cornflowerblue;\n}\n.peerConnectionState-connecting {\n  color: orange;\n}\n.peerConnectionState-connected {\n  color: green;\n}\n.peerConnectionState-disconnected,\n.peerConnectionState-closed,\n.peerConnectionState-failed {\n  color: red;\n}\n\n.iceConnectionState-new {\n  color: cornflowerblue;\n}\n.iceConnectionState-checking {\n  color: orange;\n}\n.iceConnectionState-connected,\n.iceConnectionState-completed {\n  color: green;\n}\n.peerConnectionState-disconnected,\n.peerConnectionState-closed,\n.peerConnectionState-failed {\n  color: red;\n}\n\n.iceGatheringState-new {\n  color: cornflowerblue;\n}\n.iceGatheringState-gathering {\n  color: orange;\n}\n.iceGatheringState-complete {\n  color: black;\n}\n\n.signalingState-stable {\n  color: green;\n}\n.signalingState-have-local-offer,\n.signalingState-have-remote-offer,\n.signalingState-have-local-pranswer,\n.signalingState-have-remote-pranswer {\n  color: cornflowerblue;\n}\n.signalingState-closed {\n  color: red;\n}\n\n.streamingState-streaming {\n  color: green;\n}\n\n.streamingState-empty {\n  color: grey;\n}\n\n#agentId-label, #chatId-label{\n  color: green;\n}\n\n/* added css from here */\n\nbody * {\n  font-family: 'Mulish', sans-serif;\n  text-align: center;\n}\n\n#content {\n  display: flex;\n  flex-direction: row;\n  justify-content: space-evenly;\n  margin-top: 50px;\n}\n\n#buttons {\n  clear: both;\n  padding: 0 0 0 0;\n  text-align: center;\n}\n\nbutton {\n  padding: 10px 20px;\n  border-radius: 5px;\n  border: none;\n  font-size: 16px;\n  margin: 0 5px;\n  background-color: #7459fe;\n  color: #fff;\n}\n\nbutton#connect-button {\nbackground-color: green;\n}\nbutton#destroy-button{\n  background-color: red;\n}\n\nbutton#start-button{\n  margin: 1em;\n}\n\nbutton:hover, #destroy-button:hover,#connect-button:hover {\n  filter: brightness(85%);\n  cursor: pointer;\n  transition: all 0.2s ease-out;\n}\n\nh4{\n  margin: 0;\n  margin-bottom: 10px;\n}\n\n#destroy-button, #connect-button {\n  display: none;\n}\n\ntextarea {\n  font-size: 16px;\n  text-align: center;\n  width: 500px;\n  border-radius: 5px;\n  padding: 10px 20px;\n  border: 2px solid #7459fe;\n  font-size: 16px;\n  margin: 0 5px;\n}\n\n#msgHistory {\n  overflow-y: auto;\n  line-break: loose;\n}\n\n#status {\n  display: inline-block;\n  zoom: 1;\n  line-height: 140%;\n  font-size: 15px;\n  width: 400px;\n}\n\n#status div {\n  padding-bottom: 10px;\n}\n\n#video-wrapper {\n  /* height: 500px; */\n  width: 400px;\n  height: 400px;\n  background-position: top;\n}\n\n.chat{\n  width: 400px;\n}\n\n\nvideo {\n  /* display: block; */\n  border-radius: 50%;\n  background-image: url(\"emma_idle.png\");\n  background-position: top;\n  /* position: absolute; */\n  background-size: contain;\n}\n\n.animated {\n  animation: opacityAnimation 0.2s ease-in-out;\n}\n\n@keyframes opacityAnimation {\nfrom { opacity: 0.8; }\nto { opacity: 1; }\n}\n\n--END--\n\n\n\n\n\n\n\n\n---\n\n\ncommunity updates and suggestions\n---\nagents-client-api.js\nOriginal file line number\tDiff line number\tDiff line change\n@@ -1,5 +1,6 @@\n'use strict';\n- import DID_API from './api.json' assert { type: 'json' };\n+ const fetchJsonFile = await fetch(\"./api.json\")\n+ const DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\n@@ -167,7 +168,7 @@ function onTrack(event) {\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n      if (report.type === 'inbound-rtp' && report.mediaType === 'video') {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n@@ -370,7 +371,7 @@ destroyButton.onclick = async () => {\nasync function agentsAPIworkflow() {\n  agentIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  chatIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  - axios.defaults.baseURL = 'https://api.d-id.com/';\n  + axios.defaults.baseURL = `${DID_API.url}`;\n  axios.defaults.headers.common['Authorization'] = `Basic ${DID_API.key}`\n  axios.defaults.headers.common['content-type'] = 'application/json'\n\n@@ -509,4 +510,4 @@ agentsButton.onclick = async () => {\n\n// Paste Your Created Agent and Chat IDs Here:\nagentId = \"\"\n- chatId = \"\"\nchatId = \"\"\n\n\n\nCross-browser support fixes\nShowing 1 changed file with 3 additions and 2 deletions.\n  5 changes: 3 additions & 2 deletions5  \nstreaming-client-api.js\nOriginal file line number\tDiff line number\tDiff line change\n@@ -1,5 +1,6 @@\n'use strict';\nimport DID_API from './api.json' assert { type: 'json' };\nconst fetchJsonFile = await fetch(\"./api.json\")\nconst DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\n@@ -245,7 +246,7 @@ function onTrack(event) {\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n      if (report.type === 'inbound-rtp' && report.mediaType === 'video') {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n        if (videoStatusChanged) {\n\n\n\ndefault stream warmup true\n\nShowing 1 changed file with 1 addition and 1 deletion.\n  2 changes: 1 addition & 1 deletion2  \nstreaming-client-api.js\nOriginal file line number\tDiff line number\tDiff line change\n@@ -21,7 +21,7 @@ let videoIsPlaying = false;\nlet streamVideoOpacity = 0;\n\n// Set this variable to true to request stream warmup upon connection to mitigate potential jittering issues\n- const stream_warmup = false;\n+ const stream_warmup = true;\nlet isStreamReady = !stream_warmup;\n\nconst idleVideoElement = document.getElementById('idle-video-element');\n\n\nidle streaming demo\n main (#33)\n@osimhi213\nosimhi213 committed on Apr 24 \n1 parent 93a844c\ncommit a40acb4\n \nShowing 2 changed files with 157 additions and 32 deletions.\nFilter changed files\n  37 changes: 29 additions & 8 deletions37  \nindex.html\nOriginal file line number\tDiff line number\tDiff line change\n@@ -5,10 +5,7 @@\n    <!-- added google fonts -->\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n    <link\n      href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\"\n      rel=\"stylesheet\"\n    />\n    <link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\" rel=\"stylesheet\" />\n\n    <style>\n      .peerConnectionState-new {\n@@ -73,6 +70,26 @@\n        color: grey;\n      }\n\n      .streamEvent-started {\n        color: green;\n      }\n\n      .streamEvent-stop {\n        color: orange;\n      }\n\n      .streamEvent-ready {\n        color: green;\n      }\n\n      .streamEvent-error {\n        color: red;\n      }\n\n      .streamEvent-dont-care {\n        color: gray;\n      }\n\n      /* added css from here */\n\n      body * {\n@@ -129,12 +146,15 @@\n      }\n\n      #video-wrapper div {\n        position: relative;\n        height: 100%;\n        width: 400px;\n        margin: 0 auto;\n        padding: 50px 0 0 0;\n      }\n      video {\n        position: absolute;\n        display: block;\n        object-fit: cover;\n        /*border:1px solid;*/\n        border-radius: 50%;\n        background-color: #fff;\n@@ -148,7 +168,8 @@\n      <!-- added \"id=video-wrapper\" -->\n      <div id=\"video-wrapper\">\n        <div>\n          <video id=\"video-element\" width=\"400\" height=\"400\" autoplay></video>\n          <video id=\"idle-video-element\" width=\"400\" height=\"400\" autoplay loop style=\"opacity: 1\"></video>\n          <video id=\"stream-video-element\" width=\"400\" height=\"400\" autoplay style=\"opacity: 0\"></video>\n        </div>\n      </div>\n      <br />\n@@ -163,11 +184,11 @@\n      <!-- added div#status -->\n      <div id=\"status\">\n        <!-- removed the wrapping <div> tags -->\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label\n        ><br />\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label><br />\n        ICE status: <label id=\"ice-status-label\"></label><br />\n        Peer connection status: <label id=\"peer-status-label\"></label><br />\n        Signaling status: <label id=\"signaling-status-label\"></label><br />\n        Last stream event: <label id=\"stream-event-label\"></label><br />\n        Streaming status: <label id=\"streaming-status-label\"></label><br />\n      </div>\n    </div>\n  152 changes: 128 additions & 24 deletions152  \nstreaming-client-api.js\nOriginal file line number\tDiff line number\tDiff line change\n@@ -10,31 +10,40 @@ const RTCPeerConnection = (\n).bind(window);\n\nlet peerConnection;\nlet pcDataChannel;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\n\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet videoIsPlaying = false;\nlet streamVideoOpacity = 0;\n\nconst videoElement = document.getElementById('video-element');\nvideoElement.setAttribute('playsinline', '');\n// Set this variable to true to request stream warmup upon connection to mitigate potential jittering issues\nconst stream_warmup = false;\nlet isStreamReady = !stream_warmup;\n\nconst idleVideoElement = document.getElementById('idle-video-element');\nconst streamVideoElement = document.getElementById('stream-video-element');\nidleVideoElement.setAttribute('playsinline', '');\nstreamVideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\nconst streamEventLabel = document.getElementById('stream-event-label');\n\nconst presenterInputByService = {\n  talks: {\n    source_url: 'https://d-id-public-bucket.s3.amazonaws.com/or-roman.jpg',\n  },\n  clips: {\n    presenter_id: 'rian-lZC6MmWfC1',\n    driver_id: 'mXra4jY38i'\n  }\n}\n    driver_id: 'mXra4jY38i',\n  },\n};\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n@@ -45,13 +54,18 @@ connectButton.onclick = async () => {\n  stopAllStreams();\n  closePC();\n\n  /**\n   * Set 'stream_warmup' to 'true' in the payload to initiate idle streaming at the beginning of the connection, addressing jittering issues.\n   * The idle streaming process is transparent to the user and is concealed by triggering a 'stream/ready' event on the data channel,\n   * indicating that idle streaming has concluded and the stream channel is ready for use.\n   */\n  const sessionResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(presenterInputByService[DID_API.service]),\n    body: JSON.stringify({ ...presenterInputByService[DID_API.service], stream_warmup }),\n  });\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n@@ -83,7 +97,10 @@ connectButton.onclick = async () => {\nconst startButton = document.getElementById('start-button');\nstartButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') {\n  if (\n    (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') &&\n    isStreamReady\n  ) {\n    const playResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n@@ -97,8 +114,8 @@ startButton.onclick = async () => {\n        },\n        ...(DID_API.service === 'clips' && {\n          background: {\n            color: '#FFFFFF'\n          }\n            color: '#FFFFFF',\n          },\n        }),\n        config: {\n          stitch: true,\n@@ -146,6 +163,18 @@ function onIceCandidate(event) {\n        session_id: sessionId,\n      }),\n    });\n  } else {\n    // For the initial 2 sec idle stream at the beginning of the connection, we utilize a null ice candidate.\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        session_id: sessionId,\n      }),\n    });\n  }\n}\nfunction onIceConnectionStateChange() {\n@@ -160,6 +189,21 @@ function onConnectionStateChange() {\n  // not supported in firefox\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n  if (peerConnection.connectionState === 'connected') {\n    playIdleVideo();\n    /**\n     * A fallback mechanism: if the 'stream/ready' event isn't received within 5 seconds after asking for stream warmup,\n     * it updates the UI to indicate that the system is ready to start streaming data.\n     */\n    setTimeout(() => {\n      if (!isStreamReady) {\n        console.log('forcing stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }\n    }, 5000);\n  }\n}\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n@@ -168,14 +212,19 @@ function onSignalingStateChange() {\n\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n\n  if (videoIsPlaying) {\n    status = 'streaming';\n    const remoteStream = stream;\n    setVideoElement(remoteStream);\n    streamVideoOpacity = isStreamReady ? 1 : 0;\n    setStreamVideoElement(stream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n    streamVideoOpacity = 0;\n  }\n\n  streamVideoElement.style.opacity = streamVideoOpacity;\n  idleVideoElement.style.opacity = 1 - streamVideoOpacity;\n\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n}\n@@ -209,15 +258,64 @@ function onTrack(event) {\n  }, 500);\n}\n\nfunction onStreamEvent(message) {\n  /**\n   * This function handles stream events received on the data channel.\n   * The 'stream/ready' event received on the data channel signals the end of the 2sec idle streaming.\n   * Upon receiving the 'ready' event, we can display the streamed video if one is available on the stream channel.\n   * Until the 'ready' event is received, we hide any streamed video.\n   * Additionally, this function processes events for stream start, completion, and errors. Other data events are disregarded.\n   */\n\n  if (pcDataChannel.readyState === 'open') {\n    let status;\n    const [event, _] = message.data.split(':');\n\n    switch (event) {\n      case 'stream/started':\n        status = 'started';\n        break;\n      case 'stream/done':\n        status = 'stop';\n        break;\n      case 'stream/ready':\n        status = 'ready';\n        break;\n      case 'stream/error':\n        status = 'error';\n        break;\n      default:\n        status = 'dont-care';\n        break;\n    }\n\n    // Set stream ready after a short delay, adjusting for potential timing differences between data and stream channels\n    if (status === 'ready') {\n      setTimeout(() => {\n        console.log('stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }, 1000);\n    } else {\n      console.log(event);\n      streamEventLabel.innerText = status === 'dont-care' ? event : status;\n      streamEventLabel.className = 'streamEvent-' + status;\n    }\n  }\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({ iceServers });\n    pcDataChannel = peerConnection.createDataChannel('JanusDataChannel');\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n    pcDataChannel.addEventListener('message', onStreamEvent, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n@@ -232,31 +330,32 @@ async function createPeerConnection(offer, iceServers) {\n  return sessionClientAnswer;\n}\n\nfunction setVideoElement(stream) {\nfunction setStreamVideoElement(stream) {\n  if (!stream) return;\n  videoElement.srcObject = stream;\n  videoElement.loop = false;\n\n  streamVideoElement.srcObject = stream;\n  streamVideoElement.loop = false;\n  streamVideoElement.mute = !isStreamReady;\n\n  // safari hotfix\n  if (videoElement.paused) {\n    videoElement\n  if (streamVideoElement.paused) {\n    streamVideoElement\n      .play()\n      .then((_) => {})\n      .catch((e) => {});\n  }\n}\n\nfunction playIdleVideo() {\n  videoElement.srcObject = undefined;\n  videoElement.src = DID_API.service == 'clips' ? 'rian_idle.mp4' : 'or_idle.mp4';\n  videoElement.loop = true;\n  idleVideoElement.src = DID_API.service == 'clips' ? 'rian_idle.mp4' : 'or_idle.mp4';\n}\n\nfunction stopAllStreams() {\n  if (videoElement.srcObject) {\n  if (streamVideoElement.srcObject) {\n    console.log('stopping video streams');\n    videoElement.srcObject.getTracks().forEach((track) => track.stop());\n    videoElement.srcObject = null;\n    streamVideoElement.srcObject.getTracks().forEach((track) => track.stop());\n    streamVideoElement.srcObject = null;\n    streamVideoOpacity = 0;\n  }\n}\n\n@@ -270,11 +369,16 @@ function closePC(pc = peerConnection) {\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  pc.removeEventListener('onmessage', onStreamEvent, true);\n\n  clearInterval(statsIntervalId);\n  isStreamReady = !stream_warmup;\n  streamVideoOpacity = 0;\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  streamEventLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n\n\n\nAlon Safari and Firefox fixes #36\n Merged\nalonso-balonso merged 3 commits into main from Alon-Safari-FF-Fixes  3 weeks ago\n+9 −7 \n Conversation 2\n Commits 3\n Checks 2\n Files changed 3\n Merged\nAlon Safari and Firefox fixes\n#36\n \nFile filter \n \n0 / 3 files viewed\nFilter changed files\n  9 changes: 5 additions & 4 deletions9  \nagents-client-api.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -1,5 +1,6 @@\n'use strict';\nimport DID_API from './api.json' assert { type: 'json' };\nconst fetchJsonFile = await fetch(\"./api.json\")\nconst DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\n@@ -167,7 +168,7 @@ function onTrack(event) {\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n      if (report.type === 'inbound-rtp' && report.mediaType === 'video') {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n@@ -370,7 +371,7 @@ destroyButton.onclick = async () => {\nasync function agentsAPIworkflow() {\n  agentIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  chatIdLabel.innerHTML = `<span style='color:orange'>Processing...<style='color:orange'>`\n  axios.defaults.baseURL = 'https://api.d-id.com/';\n  axios.defaults.baseURL = `${DID_API.url}`;\n  axios.defaults.headers.common['Authorization'] = `Basic ${DID_API.key}`\n  axios.defaults.headers.common['content-type'] = 'application/json'\n\n@@ -509,4 +510,4 @@ agentsButton.onclick = async () => {\n\n// Paste Your Created Agent and Chat IDs Here:\nagentId = \"\"\nchatId = \"\"\nchatId = \"\"\n  2 changes: 1 addition & 1 deletion2  \napp.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -18,4 +18,4 @@ app.get('/agents', function(req, res) {\n\nconst server = http.createServer(app);\n\nserver.listen(port, () => console.log(`Server started on port localhost:${port}`));\nserver.listen(port, () => console.log(`Server started on port localhost:${port}\\nhttp://localhost:${port}\\nhttp://localhost:${port}/agents`));\nalonso-balonso marked this conversation as resolved.\n  5 changes: 3 additions & 2 deletions5  \nstreaming-client-api.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -1,5 +1,6 @@\n'use strict';\nimport DID_API from './api.json' assert { type: 'json' };\nconst fetchJsonFile = await fetch(\"./api.json\")\nconst DID_API = await fetchJsonFile.json()\n\nif (DID_API.key == '🤫') alert('Please put your api key inside ./api.json and restart..');\n\n@@ -245,7 +246,7 @@ function onTrack(event) {\n  statsIntervalId = setInterval(async () => {\n    const stats = await peerConnection.getStats(event.track);\n    stats.forEach((report) => {\n      if (report.type === 'inbound-rtp' && report.mediaType === 'video') {\n     if (report.type === 'inbound-rtp' && report.kind === 'video') {\n        const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n        if (videoStatusChanged) {\n\n\nFeature/idle streaming mechanism demo #33\n Merged\nbenyael15 merged 5 commits into main from feature/idle-streaming-mechanism-demo  on Apr 30\n+160 −33 \n Conversation 0\n Commits 5\n Checks 2\n Files changed 2\n Merged\nFeature/idle streaming mechanism demo\n#33\n \nFile filter \n \n0 / 2 files viewed\nFilter changed files\n  41 changes: 32 additions & 9 deletions41  \nindex.html\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -5,10 +5,7 @@\n    <!-- added google fonts -->\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n    <link\n      href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\"\n      rel=\"stylesheet\"\n    />\n    <link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;700&display=swap\" rel=\"stylesheet\" />\n\n    <style>\n      .peerConnectionState-new {\n@@ -73,6 +70,26 @@\n        color: grey;\n      }\n\n      .streamEvent-started {\n        color: green;\n      }\n\n      .streamEvent-done {\n        color: orange;\n      }\n\n      .streamEvent-ready {\n        color: green;\n      }\n\n      .streamEvent-error {\n        color: red;\n      }\n\n      .streamEvent-dont-care {\n        color: gray;\n      }\n\n      /* added css from here */\n\n      body * {\n@@ -129,12 +146,17 @@\n      }\n\n      #video-wrapper div {\n        position: relative;\n        height: 100%;\n        width: 400px;\n        margin: 0 auto;\n        padding: 50px 0 0 0;\n      }\n\n      video {\n        display: block;\n        position: absolute;\n        top: 50%;\n        left: 50%;\n        transform: translate(-50%, -50%);\n        /*border:1px solid;*/\n        border-radius: 50%;\n        background-color: #fff;\n@@ -148,7 +170,8 @@\n      <!-- added \"id=video-wrapper\" -->\n      <div id=\"video-wrapper\">\n        <div>\n          <video id=\"video-element\" width=\"400\" height=\"400\" autoplay></video>\n          <video id=\"idle-video-element\" width=\"400\" height=\"400\" autoplay loop style=\"opacity: 1\"></video>\n          <video id=\"stream-video-element\" width=\"400\" height=\"400\" autoplay style=\"opacity: 0\"></video>\n        </div>\n      </div>\n      <br />\n@@ -163,11 +186,11 @@\n      <!-- added div#status -->\n      <div id=\"status\">\n        <!-- removed the wrapping <div> tags -->\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label\n        ><br />\n        ICE gathering status: <label id=\"ice-gathering-status-label\"></label><br />\n        ICE status: <label id=\"ice-status-label\"></label><br />\n        Peer connection status: <label id=\"peer-status-label\"></label><br />\n        Signaling status: <label id=\"signaling-status-label\"></label><br />\n        Last stream event: <label id=\"stream-event-label\"></label><br />\n        Streaming status: <label id=\"streaming-status-label\"></label><br />\n      </div>\n    </div>\n  152 changes: 128 additions & 24 deletions152  \nstreaming-client-api.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -10,31 +10,40 @@ const RTCPeerConnection = (\n).bind(window);\n\nlet peerConnection;\nlet pcDataChannel;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\n\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet videoIsPlaying = false;\nlet streamVideoOpacity = 0;\n\nconst videoElement = document.getElementById('video-element');\nvideoElement.setAttribute('playsinline', '');\n// Set this variable to true to request stream warmup upon connection to mitigate potential jittering issues\nconst stream_warmup = true;\nlet isStreamReady = !stream_warmup;\n\nconst idleVideoElement = document.getElementById('idle-video-element');\nconst streamVideoElement = document.getElementById('stream-video-element');\nidleVideoElement.setAttribute('playsinline', '');\nstreamVideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\nconst streamEventLabel = document.getElementById('stream-event-label');\n\nconst presenterInputByService = {\n  talks: {\n    source_url: 'https://d-id-public-bucket.s3.amazonaws.com/or-roman.jpg',\n  },\n  clips: {\n    presenter_id: 'rian-lZC6MmWfC1',\n    driver_id: 'mXra4jY38i'\n  }\n}\n    driver_id: 'mXra4jY38i',\n  },\n};\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n@@ -45,13 +54,18 @@ connectButton.onclick = async () => {\n  stopAllStreams();\n  closePC();\n\n  /**\n   * Set 'stream_warmup' to 'true' in the payload to initiate idle streaming at the beginning of the connection, addressing jittering issues.\n   * The idle streaming process is transparent to the user and is concealed by triggering a 'stream/ready' event on the data channel,\n   * indicating that idle streaming has concluded and the stream channel is ready for use.\n   */\n  const sessionResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(presenterInputByService[DID_API.service]),\n    body: JSON.stringify({ ...presenterInputByService[DID_API.service], stream_warmup }),\n  });\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n@@ -83,7 +97,10 @@ connectButton.onclick = async () => {\nconst startButton = document.getElementById('start-button');\nstartButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') {\n  if (\n    (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') &&\n    isStreamReady\n  ) {\n    const playResponse = await fetchWithRetries(`${DID_API.url}/${DID_API.service}/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n@@ -97,8 +114,8 @@ startButton.onclick = async () => {\n        },\n        ...(DID_API.service === 'clips' && {\n          background: {\n            color: '#FFFFFF'\n          }\n            color: '#FFFFFF',\n          },\n        }),\n        config: {\n          stitch: true,\n@@ -146,6 +163,18 @@ function onIceCandidate(event) {\n        session_id: sessionId,\n      }),\n    });\n  } else {\n    // For the initial 2 sec idle stream at the beginning of the connection, we utilize a null ice candidate.\n    fetch(`${DID_API.url}/${DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        session_id: sessionId,\n      }),\n    });\n  }\n}\nfunction onIceConnectionStateChange() {\n@@ -160,6 +189,21 @@ function onConnectionStateChange() {\n  // not supported in firefox\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n  if (peerConnection.connectionState === 'connected') {\n    playIdleVideo();\n    /**\n     * A fallback mechanism: if the 'stream/ready' event isn't received within 5 seconds after asking for stream warmup,\n     * it updates the UI to indicate that the system is ready to start streaming data.\n     */\n    setTimeout(() => {\n      if (!isStreamReady) {\n        console.log('forcing stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }\n    }, 5000);\n  }\n}\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n@@ -168,14 +212,19 @@ function onSignalingStateChange() {\n\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n\n  if (videoIsPlaying) {\n    status = 'streaming';\n    const remoteStream = stream;\n    setVideoElement(remoteStream);\n    streamVideoOpacity = isStreamReady ? 1 : 0;\n    setStreamVideoElement(stream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n    streamVideoOpacity = 0;\n  }\n\n  streamVideoElement.style.opacity = streamVideoOpacity;\n  idleVideoElement.style.opacity = 1 - streamVideoOpacity;\n\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n}\n@@ -209,15 +258,64 @@ function onTrack(event) {\n  }, 500);\n}\n\nfunction onStreamEvent(message) {\n  /**\n   * This function handles stream events received on the data channel.\n   * The 'stream/ready' event received on the data channel signals the end of the 2sec idle streaming.\n   * Upon receiving the 'ready' event, we can display the streamed video if one is available on the stream channel.\n   * Until the 'ready' event is received, we hide any streamed video.\n   * Additionally, this function processes events for stream start, completion, and errors. Other data events are disregarded.\n   */\n\n  if (pcDataChannel.readyState === 'open') {\n    let status;\n    const [event, _] = message.data.split(':');\n\n    switch (event) {\n      case 'stream/started':\n        status = 'started';\n        break;\n      case 'stream/done':\n        status = 'done';\n        break;\n      case 'stream/ready':\n        status = 'ready';\n        break;\n      case 'stream/error':\n        status = 'error';\n        break;\n      default:\n        status = 'dont-care';\n        break;\n    }\n\n    // Set stream ready after a short delay, adjusting for potential timing differences between data and stream channels\n    if (status === 'ready') {\n      setTimeout(() => {\n        console.log('stream/ready');\n        isStreamReady = true;\n        streamEventLabel.innerText = 'ready';\n        streamEventLabel.className = 'streamEvent-ready';\n      }, 1000);\n    } else {\n      console.log(event);\n      streamEventLabel.innerText = status === 'dont-care' ? event : status;\n      streamEventLabel.className = 'streamEvent-' + status;\n    }\n  }\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    peerConnection = new RTCPeerConnection({ iceServers });\n    pcDataChannel = peerConnection.createDataChannel('JanusDataChannel');\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n    pcDataChannel.addEventListener('message', onStreamEvent, true);\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n@@ -232,31 +330,32 @@ async function createPeerConnection(offer, iceServers) {\n  return sessionClientAnswer;\n}\n\nfunction setVideoElement(stream) {\nfunction setStreamVideoElement(stream) {\n  if (!stream) return;\n  videoElement.srcObject = stream;\n  videoElement.loop = false;\n\n  streamVideoElement.srcObject = stream;\n  streamVideoElement.loop = false;\n  streamVideoElement.mute = !isStreamReady;\n\n  // safari hotfix\n  if (videoElement.paused) {\n    videoElement\n  if (streamVideoElement.paused) {\n    streamVideoElement\n      .play()\n      .then((_) => {})\n      .catch((e) => {});\n  }\n}\n\nfunction playIdleVideo() {\n  videoElement.srcObject = undefined;\n  videoElement.src = DID_API.service == 'clips' ? 'rian_idle.mp4' : 'or_idle.mp4';\n  videoElement.loop = true;\n  idleVideoElement.src = DID_API.service == 'clips' ? 'rian_idle.mp4' : 'or_idle.mp4';\n}\n\nfunction stopAllStreams() {\n  if (videoElement.srcObject) {\n  if (streamVideoElement.srcObject) {\n    console.log('stopping video streams');\n    videoElement.srcObject.getTracks().forEach((track) => track.stop());\n    videoElement.srcObject = null;\n    streamVideoElement.srcObject.getTracks().forEach((track) => track.stop());\n    streamVideoElement.srcObject = null;\n    streamVideoOpacity = 0;\n  }\n}\n\n@@ -270,11 +369,16 @@ function closePC(pc = peerConnection) {\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  pc.removeEventListener('onmessage', onStreamEvent, true);\n\n  clearInterval(statsIntervalId);\n  isStreamReady = !stream_warmup;\n  streamVideoOpacity = 0;\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  streamEventLabel.innerText = '';\n  console.log('stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n\n\n\n\nFixed the function fetchWithRetries from streaming-client.js #24\n Open\nscgreenhalgh wants to merge 2 commits into de-id:main from scgreenhalgh:main  \n+6 −1 \n Conversation 0\n Commits 2\n Checks 0\n Files changed 1\nFile filter \n \n0 / 1 files viewed\n  7 changes: 6 additions & 1 deletion7  \nstreaming-client-api.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -391,7 +391,12 @@ const maxDelaySec = 4;\n\nasync function fetchWithRetries(url, options, retries = 1) {\n  try {\n    return await fetch(url, options);\n    const res = await fetch(url, options);\n    if(res.status >= 200 && res.status <= 299) {\n      return res;\n    } else {\n      throw new Error(`Response status ${res.status}`);\n    }\n  } catch (err) {\n    if (retries <= maxRetryCount) {\n      const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 1000;\n\n\nAdd logging with timing information #16\n Closed\njuberti wants to merge 1 commit into de-id:main from juberti:main \n+9 −3 \n Conversation 3\n Commits 1\n Checks 0\n Files changed 1\n Closed\nAdd logging with timing information\n#16\nFile filter \n \n0 / 1 files viewed\n  12 changes: 9 additions & 3 deletions12  \nstreaming-client-api.js\nViewed\nOriginal file line number\tDiff line number\tDiff line change\n@@ -17,6 +17,7 @@ let sessionClientAnswer;\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet lastTalkStartedMillis;\n\nconst talkVideo = document.getElementById('talk-video');\ntalkVideo.setAttribute('playsinline', '');\n@@ -76,6 +77,7 @@ const talkButton = document.getElementById('talk-button');\ntalkButton.onclick = async () => {\n  // connectionState not supported in firefox\n  if (peerConnection?.signalingState === 'stable' || peerConnection?.iceConnectionState === 'connected') {\n    lastTalkStartedMillis = performance.now();\n    const talkResponse = await fetchWithRetries(`${DID_API.url}/talks/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n@@ -94,6 +96,9 @@ talkButton.onclick = async () => {\n        session_id: sessionId,\n      }),\n    });\n    console.log(`talk API response latency: ${(performance.now() - lastTalkStartedMillis).toFixed(0)} ms`);\n  } else {\n    console.warn('talk button clicked before connection was established');\n  }\n};\n\n@@ -117,7 +122,7 @@ function onIceGatheringStateChange() {\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n}\nfunction onIceCandidate(event) {\n  console.log('onIceCandidate', event);\n  console.log('onIceCandidate', event.candidate);\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n@@ -160,6 +165,7 @@ function onVideoStatusChange(videoIsPlaying, stream) {\n    status = 'streaming';\n    const remoteStream = stream;\n    setVideoElement(remoteStream);\n    console.log(`video streaming latency: ${(performance.now() - lastTalkStartedMillis).toFixed(0)} ms`);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n@@ -174,7 +180,7 @@ function onTrack(event) {\n   * that's being streamed - It does so by periodically looking for changes in total stream data size\n   *\n   * This information in our case is used in order to show idle video while no talk is streaming.\n   * To create this idle video use the POST https://api.d-id.com/talks endpoint with a silent audio file or a text script with only ssml breaks \n   * To create this idle video use the POST https://api.d-id.com/talks endpoint with a silent audio file or a text script with only ssml breaks\n   * https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html#break-tag\n   * for seamless results use `config.fluent: true` and provide the same configuration as the streaming video\n   */\n@@ -194,7 +200,7 @@ function onTrack(event) {\n        lastBytesReceived = report.bytesReceived;\n      }\n    });\n  }, 500);\n  }, 100);\n}\n\nasync function createPeerConnection(offer, iceServers) {\n\n\n---\n\n\nTask:\n\n---\n\nI have this repo which was forked from https://github.com/de-id/live-streaming-demo.\n\nI have made significant modifications, swapping to the talks endpoint of d-id and then using groq for LLM and ddepgram for transcription, and the d-id still does the video generation.\n\n\n- Overall optimize for performance in speed of response. We want the app to respond to a users voice as fast as possible. Meaning we need to optimize for the fastest speed of voice->transcription->video response.\n\n- I know we've had some issues with the audio codecs, but try your best to use the fastest codecs in terms of how fast it can stream and play for the client. You may need to adjust the stream configuration parameters if changes are made the same way we made it work with the current codecs.\n\n- We made this repo a while back and there may be many new parameters offered by D-ID, Groq, and deepgram. Please review the docs and adjust the configuration parameters utilizing the latest if needed to get the responses as fast and fluent as possible. \n\n- There are many commits, PR's and other suggestions by the community I've highlighted as well. Please review these and incorporate them if they make they improve the app. \n\n- Add some logging for all the important steps. Add a basic logs and advanced logs, and add a variable I can set to easily change between the log levels\n\n- For the advanced logs add logs for the transcriptions so we can tweak the precise timing of the transcription chunks\n\n\n- Make it easy to change the appearance of the avatar, by allowing to specify the input images or videos needed by D-ID to create the moving avatar. Add comments to make it clear.\n\n- obfiscate the keys from the public repo by putting them or the current file into gitignore and I will manually put the file onto the server.\n\n- If there are any updates or improvements to the implementation of Groq, Deepgram, or D-ID, please implement them.\n\n- add a keep alive strategy for D-ID which required we send something frequently to keep everything connected. Look at the documentation for how to do this.\n\n\nTake this feedback, review all the documentation, and provide all the changes you think would improve the app. \n\nBe sure to only provide whole files or whole functions, no partial files or functions. \nIf it is a new function or file, specify where to put it.\n\n---\n"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "Certainly! I'll review the documentation, community suggestions, and implement improvements to optimize performance, enhance features, and address the points you've mentioned. I'll provide whole files or functions with explanations on where to place new additions.\n\nLet's start with the main changes:\n\n1. agents-client-api.js\n\nThis file needs significant updates to incorporate the latest features, optimize performance, and implement logging. Here's the updated version:\n\n```javascript\n'use strict';\n\n// Import configuration\nimport config from './config.js';\n\n// Logging setup\nconst LOG_LEVELS = {\n  BASIC: 'basic',\n  ADVANCED: 'advanced'\n};\nconst currentLogLevel = LOG_LEVELS.BASIC; // Change to LOG_LEVELS.ADVANCED for detailed logs\n\nfunction log(message, level = LOG_LEVELS.BASIC) {\n  if (level === currentLogLevel || currentLogLevel === LOG_LEVELS.ADVANCED) {\n    console.log(`[${new Date().toISOString()}] ${message}`);\n  }\n}\n\n// WebRTC setup\nconst RTCPeerConnection = (\n  window.RTCPeerConnection ||\n  window.webkitRTCPeerConnection ||\n  window.mozRTCPeerConnection\n).bind(window);\n\nlet peerConnection;\nlet streamId;\nlet sessionId;\nlet sessionClientAnswer;\nlet statsIntervalId;\nlet videoIsPlaying;\nlet lastBytesReceived;\nlet chatHistory = [];\nlet mediaRecorder;\nlet deepgramSocket;\nlet transcript = '';\nlet inactivityTimeout;\nlet transcriptionTimer;\nlet keepAliveInterval;\n\nconst context = `You are a helpful, harmless, and honest assistant. Please answer the users questions briefly, be concise, not more than 1 sentence unless absolutely needed.`;\n\nconst videoElement = document.getElementById('video-element');\nvideoElement.setAttribute('playsinline', '');\nconst peerStatusLabel = document.getElementById('peer-status-label');\nconst iceStatusLabel = document.getElementById('ice-status-label');\nconst iceGatheringStatusLabel = document.getElementById('ice-gathering-status-label');\nconst signalingStatusLabel = document.getElementById('signaling-status-label');\nconst streamingStatusLabel = document.getElementById('streaming-status-label');\n\nwindow.onload = async (event) => {\n  initializeIdleVideo();\n  showLoadingSymbol();\n  try {\n    await connectButton.onclick();\n    hideLoadingSymbol();\n  } catch (error) {\n    console.error('Error during auto-initialization:', error);\n    hideLoadingSymbol();\n    showErrorMessage('Failed to connect. Please try again.');\n  }\n};\n\nfunction initializeIdleVideo() {\n  videoElement.src = config.idleVideoUrl;\n  videoElement.loop = true;\n  videoElement.muted = true;\n  videoElement.playsInline = true;\n  \n  videoElement.play().catch(error => {\n    log(\"Autoplay was prevented for idle video:\", error);\n    showPlayButton();\n  });\n}\n\nfunction playIdleVideo() {\n  if (videoElement.src !== config.idleVideoUrl) {\n    videoElement.src = config.idleVideoUrl;\n  }\n  videoElement.loop = true;\n  videoElement.muted = true;\n  videoElement.currentTime = 0;\n  \n  videoElement.play().catch(error => {\n    log(\"Playback of idle video was prevented:\", error);\n    showPlayButton();\n  });\n}\n\nfunction showPlayButton() {\n  const playButton = document.createElement('button');\n  playButton.textContent = 'Play Idle Video';\n  playButton.style.position = 'absolute';\n  playButton.style.zIndex = '1000';\n  playButton.style.top = '50%';\n  playButton.style.left = '50%';\n  playButton.style.transform = 'translate(-50%, -50%)';\n  playButton.onclick = () => {\n    videoElement.play();\n    playButton.remove();\n  };\n  videoElement.parentElement.appendChild(playButton);\n}\n\nfunction setVideoElement(stream) {\n  if (!stream) {\n    log('No stream available to set video element');\n    playIdleVideo();\n    return;\n  }\n\n  videoElement.srcObject = stream;\n  videoElement.muted = false;\n  videoElement.loop = false;\n\n  videoElement.play().then(() => {\n    log('Video playback started');\n  }).catch(e => {\n    console.error('Error playing video:', e);\n    showPlayButton();\n  });\n}\n\nfunction showLoadingSymbol() {\n  const loadingSymbol = document.createElement('div');\n  loadingSymbol.id = 'loading-symbol';\n  loadingSymbol.innerHTML = 'Connecting...';\n  loadingSymbol.style.position = 'absolute';\n  loadingSymbol.style.top = '50%';\n  loadingSymbol.style.left = '50%';\n  loadingSymbol.style.transform = 'translate(-50%, -50%)';\n  loadingSymbol.style.backgroundColor = 'rgba(0, 0, 0, 0.8)';\n  loadingSymbol.style.color = 'white';\n  loadingSymbol.style.padding = '10px';\n  loadingSymbol.style.borderRadius = '5px';\n  loadingSymbol.style.zIndex = '9999';\n  document.body.appendChild(loadingSymbol);\n}\n\nfunction hideLoadingSymbol() {\n  const loadingSymbol = document.getElementById('loading-symbol');\n  if (loadingSymbol) {\n    document.body.removeChild(loadingSymbol);\n  }\n}\n\nfunction showErrorMessage(message) {\n  const errorMessage = document.createElement('div');\n  errorMessage.innerHTML = message;\n  errorMessage.style.color = 'red';\n  errorMessage.style.marginBottom = '10px';\n  document.body.appendChild(errorMessage);\n\n  destroyButton.style.display = 'inline-block';\n  connectButton.style.display = 'inline-block';\n}\n\nasync function createPeerConnection(offer, iceServers) {\n  if (!peerConnection) {\n    const config = {\n      iceServers,\n      sdpSemantics: 'unified-plan'\n    };\n    peerConnection = new RTCPeerConnection(config);\n    peerConnection.addEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n    peerConnection.addEventListener('icecandidate', onIceCandidate, true);\n    peerConnection.addEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n    peerConnection.addEventListener('connectionstatechange', onConnectionStateChange, true);\n    peerConnection.addEventListener('signalingstatechange', onSignalingStateChange, true);\n    peerConnection.addEventListener('track', onTrack, true);\n\n    peerConnection.addTransceiver('audio', {direction: 'recvonly'});\n    peerConnection.addTransceiver('video', {direction: 'recvonly'});\n  }\n\n  await peerConnection.setRemoteDescription(offer);\n  log('Set remote SDP OK', LOG_LEVELS.ADVANCED);\n\n  const sessionClientAnswer = await peerConnection.createAnswer();\n  log('Create local SDP OK', LOG_LEVELS.ADVANCED);\n\n  await peerConnection.setLocalDescription(sessionClientAnswer);\n  log('Set local SDP OK', LOG_LEVELS.ADVANCED);\n\n  return sessionClientAnswer;\n}\n\nfunction onIceGatheringStateChange() {\n  iceGatheringStatusLabel.innerText = peerConnection.iceGatheringState;\n  iceGatheringStatusLabel.className = 'iceGatheringState-' + peerConnection.iceGatheringState;\n  log(`ICE gathering state changed to: ${peerConnection.iceGatheringState}`, LOG_LEVELS.ADVANCED);\n}\n\nfunction onIceCandidate(event) {\n  if (event.candidate) {\n    const { candidate, sdpMid, sdpMLineIndex } = event.candidate;\n\n    fetch(`${config.DID_API.url}/${config.DID_API.service}/streams/${streamId}/ice`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${config.DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        candidate,\n        sdpMid,\n        sdpMLineIndex,\n        session_id: sessionId,\n      }),\n    });\n    log(`ICE candidate sent: ${JSON.stringify(event.candidate)}`, LOG_LEVELS.ADVANCED);\n  }\n}\n\nfunction onIceConnectionStateChange() {\n  iceStatusLabel.innerText = peerConnection.iceConnectionState;\n  iceStatusLabel.className = 'iceConnectionState-' + peerConnection.iceConnectionState;\n  log(`ICE connection state changed to: ${peerConnection.iceConnectionState}`);\n\n  if (peerConnection.iceConnectionState === 'failed' || peerConnection.iceConnectionState === 'closed') {\n    stopAllStreams();\n    closePC();\n    showErrorMessage('Connection lost. Please try again.');\n  }\n}\n\nfunction onConnectionStateChange() {\n  peerStatusLabel.innerText = peerConnection.connectionState;\n  peerStatusLabel.className = 'peerConnectionState-' + peerConnection.connectionState;\n  log(`Peer connection state changed to: ${peerConnection.connectionState}`);\n}\n\nfunction onSignalingStateChange() {\n  signalingStatusLabel.innerText = peerConnection.signalingState;\n  signalingStatusLabel.className = 'signalingState-' + peerConnection.signalingState;\n  log(`Signaling state changed to: ${peerConnection.signalingState}`);\n}\n\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n  if (videoIsPlaying) {\n    status = 'streaming';\n    setVideoElement(stream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n  }\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n  log(`Video status changed to: ${status}`);\n}\n\nfunction onTrack(event) {\n  log('onTrack event:', event);\n  if (!event.track) return;\n\n  if (statsIntervalId) {\n    clearInterval(statsIntervalId);\n  }\n\n  statsIntervalId = setInterval(async () => {\n    if (peerConnection && peerConnection.connectionState === 'connected') {\n      try {\n        const stats = await peerConnection.getStats(event.track);\n        stats.forEach((report) => {\n          if (report.type === 'inbound-rtp' && report.kind === 'video') {\n            const videoStatusChanged = videoIsPlaying !== report.bytesReceived > lastBytesReceived;\n\n            if (videoStatusChanged) {\n              videoIsPlaying = report.bytesReceived > lastBytesReceived;\n              onVideoStatusChange(videoIsPlaying, event.streams[0]);\n            }\n            lastBytesReceived = report.bytesReceived;\n          }\n        });\n      } catch (error) {\n        console.error('Error getting stats:', error);\n      }\n    } else {\n      log('Peer connection not ready for stats.');\n    }\n  }, 1000);\n\n  setVideoElement(event.streams[0]);\n}\n\nfunction setVideoElement(stream) {\n  if (!stream) {\n    log('No stream available to set video element');\n    return;\n  }\n\n  videoElement.srcObject = stream;\n  videoElement.muted = false;\n  videoElement.classList.add(\"animated\");\n\n  videoElement.play().then(() => {\n    log('Video playback started');\n  }).catch(e => {\n    console.error('Error playing video:', e);\n    playIdleVideo();\n  });\n\n  setTimeout(() => {\n    videoElement.classList.remove(\"animated\");\n  }, 300);\n}\n\nfunction playIdleVideo() {\n  videoElement.srcObject = undefined;\n  videoElement.src = config.idleVideoUrl;\n  videoElement.loop = true;\n  videoElement.muted = true;\n  videoElement.play().then(() => {\n    log('Idle video playback started');\n  }).catch(e => console.error('Error playing idle video:', e));\n}\n\nfunction stopAllStreams() {\n  if (videoElement.srcObject) {\n    log('Stopping video streams');\n    videoElement.srcObject.getTracks().forEach((track) => track.stop());\n    videoElement.srcObject = null;\n  }\n}\n\nfunction closePC(pc = peerConnection) {\n  if (!pc) return;\n  log('Stopping peer connection');\n  pc.close();\n  pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange, true);\n  pc.removeEventListener('icecandidate', onIceCandidate, true);\n  pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange, true);\n  pc.removeEventListener('connectionstatechange', onConnectionStateChange, true);\n  pc.removeEventListener('signalingstatechange', onSignalingStateChange, true);\n  pc.removeEventListener('track', onTrack, true);\n  clearInterval(statsIntervalId);\n  iceGatheringStatusLabel.innerText = '';\n  signalingStatusLabel.innerText = '';\n  iceStatusLabel.innerText = '';\n  peerStatusLabel.innerText = '';\n  log('Stopped peer connection');\n  if (pc === peerConnection) {\n    peerConnection = null;\n  }\n}\n\nconst maxRetryCount = 2;\nconst maxDelaySec = 2;\nasync function fetchWithRetries(url, options, retries = 1) {\n  try {\n    const response = await fetch(url, options);\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    return response;\n  } catch (err) {\n    if (retries <= maxRetryCount) {\n      const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), maxDelaySec) * 500;\n      await new Promise((resolve) => setTimeout(resolve, delay));\n      log(`Request failed, retrying ${retries}/${maxRetryCount}. Error ${err}`);\n      return fetchWithRetries(url, options, retries + 1);\n    } else {\n      throw new Error(`Max retries exceeded. error: ${err}`);\n    }\n  }\n}\n\nconst connectButton = document.getElementById('connect-button');\nconnectButton.onclick = async () => {\n  if (peerConnection && peerConnection.connectionState === 'connected') {\n    return;\n  }\n  stopAllStreams();\n  closePC();\n\n  const sessionResponse = await fetchWithRetries(`${config.DID_API.url}/${config.DID_API.service}/streams`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${config.DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      source_url: config.avatarImageUrl,\n      driver_url: 'bank://lively/',\n      output_resolution: 720,\n      stream_warmup: true,\n      config: {\n        stitch: true,\n        fluent: true,\n        pad_audio: 0,\n        auto_match: true,\n        driver_expressions: {\n          attention: 0.3,\n          surprise: 0.3,\n        },\n        motion_factor: 0.8,\n        normalization_factor: 0.8,\n        sharpen: true,\n      },\n    }),\n  });\n\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n  streamId = newStreamId"
                }
            ]
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "continue from    const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n\n"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "Certainly! I'll continue from where we left off in the `connectButton.onclick` function:\n\n```javascript\n  const { id: newStreamId, offer, ice_servers: iceServers, session_id: newSessionId } = await sessionResponse.json();\n  streamId = newStreamId;\n  sessionId = newSessionId;\n  log(`Stream created with ID: ${streamId}`, LOG_LEVELS.ADVANCED);\n\n  try {\n    sessionClientAnswer = await createPeerConnection(offer, iceServers);\n  } catch (e) {\n    console.error('Error during streaming setup', e);\n    stopAllStreams();\n    closePC();\n    return;\n  }\n\n  const sdpResponse = await fetch(`${config.DID_API.url}/${config.DID_API.service}/streams/${streamId}/sdp`, {\n    method: 'POST',\n    headers: {\n      Authorization: `Basic ${config.DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      answer: sessionClientAnswer,\n      session_id: sessionId,\n    }),\n  });\n\n  if (sdpResponse.ok) {\n    log('SDP answer sent successfully', LOG_LEVELS.ADVANCED);\n    startKeepAlive();\n  } else {\n    console.error('Error sending SDP answer:', await sdpResponse.text());\n  }\n};\n\nfunction startKeepAlive() {\n  if (keepAliveInterval) {\n    clearInterval(keepAliveInterval);\n  }\n  keepAliveInterval = setInterval(async () => {\n    try {\n      const response = await fetch(`${config.DID_API.url}/${config.DID_API.service}/streams/${streamId}/keepalive`, {\n        method: 'POST',\n        headers: {\n          Authorization: `Basic ${config.DID_API.key}`,\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ session_id: sessionId }),\n      });\n      if (response.ok) {\n        log('Keep-alive sent successfully', LOG_LEVELS.ADVANCED);\n      } else {\n        console.error('Error sending keep-alive:', await response.text());\n      }\n    } catch (error) {\n      console.error('Failed to send keep-alive:', error);\n    }\n  }, 30000); // Send keep-alive every 30 seconds\n}\n\nasync function startStreaming(assistantReply) {\n  try {\n    const startTime = performance.now();\n    const playResponse = await fetchWithRetries(`${config.DID_API.url}/${config.DID_API.service}/streams/${streamId}`, {\n      method: 'POST',\n      headers: {\n        Authorization: `Basic ${config.DID_API.key}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        script: {\n          type: 'text',\n          input: assistantReply,\n          provider: {\n            type: 'microsoft',\n            voice_id: config.voiceId\n          }\n        },\n        config: {\n          fluent: true,\n          pad_audio: 0,\n          stitch: true,\n          sharpen: true,\n          motion_factor: 0.8,\n        },\n        session_id: sessionId,\n      }),\n    });\n\n    if (playResponse.ok) {\n      const endTime = performance.now();\n      log(`Streaming request successful. Time taken: ${endTime - startTime}ms`, LOG_LEVELS.ADVANCED);\n    } else {\n      throw new Error(`HTTP error! status: ${playResponse.status}`);\n    }\n\n    videoElement.muted = false;\n  } catch (error) {\n    console.error('Error during streaming:', error);\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  }\n}\n\nasync function startRecording() {\n  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n  mediaRecorder = new MediaRecorder(stream);\n\n  deepgramSocket = new WebSocket('wss://api.deepgram.com/v1/listen', [\n    'token',\n    config.DEEPGRAM_API_KEY,\n  ]);\n\n  deepgramSocket.onopen = () => {\n    log('Deepgram WebSocket connection opened', LOG_LEVELS.ADVANCED);\n    mediaRecorder.addEventListener('dataavailable', async (event) => {\n      if (event.data.size > 0 && deepgramSocket.readyState === 1) {\n        deepgramSocket.send(event.data);\n      }\n    });\n    mediaRecorder.start(1000);\n\n    setInterval(() => {\n      if (deepgramSocket.readyState === 1) {\n        const keepAliveMsg = JSON.stringify({ type: \"KeepAlive\" });\n        deepgramSocket.send(keepAliveMsg);\n        log(\"Sent KeepAlive message to Deepgram\", LOG_LEVELS.ADVANCED);\n      }\n    }, 3000);\n\n    transcriptionTimer = setInterval(() => {\n      if (transcript.trim() !== '') {\n        document.getElementById('msgHistory').innerHTML += `<span style='opacity:0.5'><u>User:</u> ${transcript}</span><br>`;\n        chatHistory.push({\n          role: 'user',\n          content: transcript,\n        });\n        sendChatToGroq();\n        transcript = '';\n      }\n    }, 3000);\n  };\n\n  deepgramSocket.onmessage = (message) => {\n    const received = JSON.parse(message.data);\n    const partialTranscript = received.channel.alternatives[0].transcript;\n\n    if (partialTranscript) {\n      transcript += partialTranscript;\n      document.getElementById('msgHistory').innerHTML = document.getElementById('msgHistory').innerHTML.replace(/<span style='opacity:0.5'><u>User \\(interim\\):<\\/u>.*<\\/span><br>/, `<span style='opacity:0.5'><u>User (interim):</u> ${transcript}</span><br>`);\n      log(`Partial transcript: ${partialTranscript}`, LOG_LEVELS.ADVANCED);\n    }\n  };\n\n  deepgramSocket.onclose = async () => {\n    log('Deepgram WebSocket connection closed', LOG_LEVELS.ADVANCED);\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  };\n\n  inactivityTimeout = setTimeout(() => {\n    if (isRecording) {\n      log('Inactivity timeout reached. Stopping recording.');\n      startButton.click();\n    }\n  }, 45000);\n}\n\nasync function stopRecording() {\n  if (mediaRecorder && mediaRecorder.state === 'recording') {\n    mediaRecorder.stop();\n    const closeMsg = JSON.stringify({ type: \"CloseStream\" });\n    deepgramSocket.send(closeMsg);\n    deepgramSocket.close();\n    mediaRecorder = null;\n  }\n\n  clearInterval(transcriptionTimer);\n  clearTimeout(inactivityTimeout);\n}\n\nasync function sendChatToGroq() {\n  try {\n    const startTime = performance.now();\n    const response = await fetch(config.GROQ_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${config.GROQ_API_KEY}`\n      },\n      body: JSON.stringify({\n        messages: [\n          {\n            role: 'system',\n            content: context,\n          },\n          ...chatHistory,\n        ],\n        model: 'mixtral-8x7b-32768',\n        max_tokens: 150,\n        temperature: 0.7,\n        top_p: 1,\n        stream: true,\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error ${response.status}`);\n    }\n\n    const reader = response.body.getReader();\n    let assistantReply = '';\n    let done = false;\n\n    while (!done) {\n      const { value, done: readerDone } = await reader.read();\n      done = readerDone;\n\n      if (value) {\n        const chunk = new TextDecoder().decode(value);\n        const lines = chunk.split('\\n');\n\n        for (const line of lines) {\n          if (line.startsWith('data:')) {\n            const data = line.substring(5).trim();\n            if (data === '[DONE]') {\n              done = true;\n              break;\n            }\n\n            const parsed = JSON.parse(data);\n            assistantReply += parsed.choices[0]?.delta?.content || '';\n          }\n        }\n      }\n    }\n\n    const endTime = performance.now();\n    log(`Groq API response time: ${endTime - startTime}ms`, LOG_LEVELS.ADVANCED);\n\n    chatHistory.push({\n      role: 'assistant',\n      content: assistantReply,\n    });\n\n    document.getElementById('msgHistory').innerHTML += `<span><u>Assistant:</u> ${assistantReply}</span><br>`;\n\n    clearTimeout(inactivityTimeout);\n    inactivityTimeout = setTimeout(() => {\n      if (isRecording) {\n        log('Inactivity timeout reached. Stopping recording.');\n        startButton.click();\n      }\n    }, 45000);\n\n    await startStreaming(assistantReply);\n  } catch (error) {\n    console.error('Error:', error);\n    if (isRecording) {\n      await reinitializeConnection();\n    }\n  }\n}\n\nasync function reinitializeConnection() {\n  log('Reinitializing connection...', LOG_LEVELS.ADVANCED);\n  stopAllStreams();\n  closePC();\n\n  clearInterval(transcriptionTimer);\n  clearTimeout(inactivityTimeout);\n\n  transcript = '';\n  chatHistory = chatHistory.slice(0, -1);\n\n  const msgHistory = document.getElementById('msgHistory');\n  msgHistory.innerHTML = msgHistory.innerHTML.slice(0, msgHistory.innerHTML.lastIndexOf('<span style=\\'opacity:0.5\\'><u>User:</u>'));\n\n  await connectButton.onclick();\n  await startRecording();\n}\n\nconst destroyButton = document.getElementById('destroy-button');\ndestroyButton.onclick = async () => {\n  await fetch(`${config.DID_API.url}/${config.DID_API.service}/streams/${streamId}`, {\n    method: 'DELETE',\n    headers: {\n      Authorization: `Basic ${config.DID_API.key}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ session_id: sessionId }),\n  });\n\n  stopAllStreams();\n  closePC();\n  clearInterval(keepAliveInterval);\n};\n\nconst startButton = document.getElementById('start-button');\nlet isRecording = false;\n\nstartButton.onclick = async () => {\n  if (!isRecording) {\n    startButton.textContent = 'Stop';\n    await startRecording();\n  } else {\n    startButton.textContent = 'Speak';\n    await stopRecording();\n  }\n  isRecording = !isRecording;\n};\n\nexport { log, LOG_LEVELS };\n```\n\nNow, let's create a new file called `config.js` to store all the configuration parameters:\n\n```javascript\n// config.js\n\nexport default {\n  DID_API: {\n    key: process.env.DID_API_KEY,\n    url: 'https://api.d-id.com',\n    service: 'talks'\n  },\n  GROQ_API_KEY: process.env.GROQ_API_KEY,\n  GROQ_API_URL: 'https://api.groq.com/openai/v1/chat/completions',\n  DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY,\n  idleVideoUrl: 'emma_idle.mp4',\n  avatarImageUrl: 'https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg',\n  voiceId: 'en-US-JennyMultilingualV2Neural'\n};\n```\n\nTo use environment variables for API keys, you'll need to set up a `.env` file in the root of your project:\n\n```\nDID_API_KEY=your_did_api_key_here\nGROQ_API_KEY=your_groq_api_key_here\nDEEPGRAM_API_KEY=your_deepgram_api_key_here\n```\n\nMake sure to add `.env` to your `.gitignore` file to keep your API keys secure.\n\nYou'll also need to update your `package.json` to include the necessary dependencies and scripts:\n\n```json\n{\n  \"name\": \"d-id-streaming-demo\",\n  \"version\": \"1.0.0\",\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"cors\": \"^2.8.5\",\n    \"dotenv\": \"^10.0.0\",\n    \"express\": \"^4.18.2\"\n  },\n  \"scripts\": {\n    \"start\": \"node -r dotenv/config app.js\"\n  }\n}\n```\n\nLastly, update your `app.js` to use the environment variables:\n\n```javascript\nimport express from 'express';\nimport http from 'http';\nimport cors from 'cors';\nimport dotenv from 'dotenv';\n\ndotenv.config();\n\nconst port = process.env.PORT || 3000;\n\nconst app = express();\napp.use(cors());\n\napp.use('/', express.static('.', {\n  setHeaders: (res, path) => {\n    if (path.endsWith('.js')) {\n      res.setHeader('Content-Type', 'application/javascript');\n    }\n  }\n}));\n\napp.get('/', (req, res) => {\n  res.sendFile('index.html', { root: '.' });\n});\n\nconst server = http.createServer(app);\n\nserver.listen(port, () => console.log(`Server started on port ${port}\\nhttp://localhost:${port}`));\n```\n\nThese changes will:\n\n1. Optimize performance by using the latest D-ID, Groq, and Deepgram features.\n2. Implement basic and advanced logging.\n3. Make it easier to change the avatar appearance.\n4. Obfuscate API keys using environment variables.\n5. Implement a keep-alive strategy for D-ID.\n6. Improve error handling and connection reinitializ"
                }
            ]
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Uncaught SyntaxError: Identifier 'setVideoElement' has already been declared (at agents-client-api.js?__sbCache=0.47343742277698886:288:1)\n"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "I apologize for the confusion. It seems there was a duplicate function declaration. Let's fix that by removing the duplicate `setVideoElement` function and consolidating its functionality. Here's the corrected part of the `agents-client-api.js` file:\n\n```javascript\n// Remove this function as it's duplicated\n// function setVideoElement(stream) {\n//   if (!stream) {\n//     log('No stream available to set video element');\n//     playIdleVideo();\n//     return;\n//   }\n//\n//   videoElement.srcObject = stream;\n//   videoElement.muted = false;\n//   videoElement.loop = false;\n//\n//   videoElement.play().then(() => {\n//     log('Video playback started');\n//   }).catch(e => {\n//     console.error('Error playing video:', e);\n//     showPlayButton();\n//   });\n// }\n\n// Keep this function and update it to include the functionality from both\nfunction setVideoElement(stream) {\n  if (!stream) {\n    log('No stream available to set video element');\n    playIdleVideo();\n    return;\n  }\n\n  videoElement.srcObject = stream;\n  videoElement.muted = false;\n  videoElement.loop = false;\n  videoElement.classList.add(\"animated\");\n\n  videoElement.play().then(() => {\n    log('Video playback started');\n  }).catch(e => {\n    console.error('Error playing video:', e);\n    playIdleVideo();\n    showPlayButton();\n  });\n\n  setTimeout(() => {\n    videoElement.classList.remove(\"animated\");\n  }, 300);\n}\n\n// Update the onVideoStatusChange function to use setVideoElement\nfunction onVideoStatusChange(videoIsPlaying, stream) {\n  let status;\n  if (videoIsPlaying) {\n    status = 'streaming';\n    setVideoElement(stream);\n  } else {\n    status = 'empty';\n    playIdleVideo();\n  }\n  streamingStatusLabel.innerText = status;\n  streamingStatusLabel.className = 'streamingState-' + status;\n  log(`Video status changed to: ${status}`);\n}\n\n// The rest of the file remains the same\n```\n\nThis change consolidates the `setVideoElement` function and removes the duplicate declaration. The updated function now includes all the necessary functionality from both previous versions.\n\nMake sure to replace the relevant part in your `agents-client-api.js` file with this updated code. This should resolve the SyntaxError you encountered."
                }
            ]
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "agents-client-api.js?__sbCache=0.5267316394951111:298  Uncaught SyntaxError: Identifier 'playIdleVideo' has already been declared (at agents-client-api.js?__sbCache=0.5267316394951111:298:1)\n"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "I apologize for the oversight. It seems there's another duplicate function declaration. Let's consolidate the `playIdleVideo` function as well. Here's the corrected part of the `agents-client-api.js` file:\n\n```javascript\n// Remove this function as it's duplicated\n// function playIdleVideo() {\n//   videoElement.srcObject = undefined;\n//   videoElement.src = config.idleVideoUrl;\n//   videoElement.loop = true;\n//   videoElement.muted = true;\n//   videoElement.play().then(() => {\n//     log('Idle video playback started');\n//   }).catch(e => console.error('Error playing idle video:', e));\n// }\n\n// Keep this function and update it to include all necessary functionality\nfunction playIdleVideo() {\n  if (videoElement.src !== config.idleVideoUrl) {\n    videoElement.src = config.idleVideoUrl;\n  }\n  videoElement.srcObject = undefined;\n  videoElement.loop = true;\n  videoElement.muted = true;\n  videoElement.currentTime = 0;\n  \n  videoElement.play().then(() => {\n    log('Idle video playback started');\n  }).catch(error => {\n    console.error('Error playing idle video:', error);\n    log(\"Playback of idle video was prevented:\", error);\n    showPlayButton();\n  });\n}\n\n// The rest of the file remains the same\n```\n\nThis change consolidates the `playIdleVideo` function and removes the duplicate declaration. The updated function now includes all the necessary functionality from both previous versions.\n\nMake sure to replace the relevant part in your `agents-client-api.js` file with this updated code. Also, ensure that you've removed any other duplicate declarations of `playIdleVideo` in the file.\n\nAfter making these changes, the SyntaxError for duplicate declarations should be resolved. If you encounter any more issues with duplicate declarations, please review the entire file and make sure each function is declared only once, consolidating functionality where necessary."
                }
            ]
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "// config.js\n\nexport default {\n    DID_API: {\n      key: process.env.DID_API_KEY,\n      url: 'https://api.d-id.com',\n      service: 'talks'\n    },\n    GROQ_API_KEY: process.env.GROQ_API_KEY,\n    GROQ_API_URL: 'https://api.groq.com/openai/v1/chat/completions',\n    DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY,\n    idleVideoUrl: 'emma_idle.mp4',\n    avatarImageUrl: 'https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg',\n    voiceId: 'en-US-JennyMultilingualV2Neural'\n  };\n\nconfig.js?__sbCache=0.3566017831831618:5  Uncaught ReferenceError: process is not defined\n    at config.js?__sbCache=0.3566017831831618:5:12\n"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "I apologize for the confusion. The error occurs because `process.env` is not available in the browser environment. For a client-side application, we need to handle configuration differently. Let's modify the `config.js` file to use hardcoded values or values from a global object that you can set in your HTML file.\n\nHere's an updated version of `config.js`:\n\n```javascript\n// config.js\n\n// Check if we're in a browser environment\nconst isBrowser = typeof window !== 'undefined';\n\n// Use a global object for configuration if in browser\nconst globalConfig = isBrowser && window.appConfig ? window.appConfig : {};\n\nexport default {\n  DID_API: {\n    key: globalConfig.DID_API_KEY || 'your_default_did_api_key_here',\n    url: 'https://api.d-id.com',\n    service: 'talks'\n  },\n  GROQ_API_KEY: globalConfig.GROQ_API_KEY || 'your_default_groq_api_key_here',\n  GROQ_API_URL: 'https://api.groq.com/openai/v1/chat/completions',\n  DEEPGRAM_API_KEY: globalConfig.DEEPGRAM_API_KEY || 'your_default_deepgram_api_key_here',\n  idleVideoUrl: 'emma_idle.mp4',\n  avatarImageUrl: 'https://create-images-results.d-id.com/DefaultPresenters/Emma_f/v1_image.jpeg',\n  voiceId: 'en-US-JennyMultilingualV2Neural'\n};\n```\n\nThen, in your HTML file (e.g., `index.html`), you can add a script tag to set the global configuration before loading your main script:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n    <!-- Other head elements -->\n</head>\n<body>\n    <!-- Your HTML content -->\n\n    <script>\n        window.appConfig = {\n            DID_API_KEY: 'your_actual_did_api_key',\n            GROQ_API_KEY: 'your_actual_groq_api_key',\n            DEEPGRAM_API_KEY: 'your_actual_deepgram_api_key'\n        };\n    </script>\n    <script type=\"module\" src=\"agents-client-api.js\"></script>\n</body>\n</html>\n```\n\nThis approach allows you to keep your API keys out of the source code while still making them available to your client-side JavaScript. However, please note that this method is not secure for production use, as the API keys will be visible in the client-side code.\n\nFor a production environment, you should consider:\n\n1. Using environment variables on the server-side and injecting them into your HTML dynamically.\n2. Implementing a backend service to handle API calls, keeping your keys secure on the server.\n3. Using token-based authentication or other secure methods recommended by the API providers.\n\nRemember to update your `.gitignore` file to exclude any files containing sensitive information."
                }
            ]
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Ok, it's working pretty well, but the idel video and the talking video don't match up. The idle video is much more scaled up, but I can provide a new photo if needed. \n Additionally, there should be some method that makes the idle video sort of merge into the talking video. We should implement it. \n Be sure to only provide whole files or whole functions, no partial files or functions. \nIf it is a new function or file, specify where to put it."
                }
            ]
        }




